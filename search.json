[{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"setting-up-the-environment-","dir":"Articles","previous_headings":"","what":"Setting up the environment.","title":"Sampling SDP Data Products at Field Sites","text":"haven’t already, first need install relevant packages load working environment.","code":"remotes::install_github(\"rmbl-sdp/rSDP\") remotes::install_github(\"rstudio/leaflet\") install.packages(c(\"terra\",\"tidyterra\",\"sf\"),                  type=\"binary\") # `binary` install prevents dependency issues on Mac and Windows library(sf) library(terra) library(leaflet) library(rSDP)"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"reading-in-spatial-data-on-field-sites-","dir":"Articles","previous_headings":"","what":"Reading in spatial data on field sites.","title":"Sampling SDP Data Products at Field Sites","text":"R users familiar Data Frames, basic data structure tabular, spreadsheet-style data. Data Frames work great many datasets, work spatial data, need link tabular information objects describe geometry geographic feature study site sampling area. different ways :","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"tabular-data-with-coordinates","dir":"Articles","previous_headings":"Reading in spatial data on field sites.","what":"Tabular data with coordinates","title":"Sampling SDP Data Products at Field Sites","text":"simplest case, locations field sites can read along site data set spatial coordinates. simplest point data, location site can described two numbers represent X Y coordinates site (latitude longitude, example). read simple Data Frame contains coordinates: case, X Y fields represent decimal degrees latitude longitude. can let R ’know` coordinates way: code creates new object still tabular data original file, new column geometry hold spatial coordinates. Technically, data now “Simple Feature Collection”. information Simple Features, check article “Wrangling Spatial Data”. almost business! one missing piece, however. create spatial objects way, also need assign Coordinate Reference System. Basically, need let R know coordinates represent latitudes longitudes system referencing coordinates. assigning EPSG Code dataset. thousands different coordinate reference systems , codes shorthand uniquely assign coordinate system. summary longer says CRS: NA instead reads Geodetic CRS: WGS 84. tells us successfully assigned coordinate system data! make sure assigned correct one (e.g. right EPSG Code)? simplest way plot data web map. Since know points represent sites close Rocky Mountain Biological Lab Gothic, CO. can pretty sure ’ve assigned correct coordinate system. don’t know EPSG code corresponds coordinates dataset? can look code handy website epsg.io.","code":"sites_xy <- read.csv(\"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/rSDP_example_points_latlon.csv\") head(sites_xy) #>           X        Y fid         Name #> 1 -106.9904 38.96237   1        Rocky #> 2 -106.9898 38.96222   2        Aspen #> 3 -106.9903 38.96083   3         Road #> 4 -106.9934 38.96006   4   BeaverPond #> 5 -106.9927 38.96023   5 GrassyMeadow #> 6 -106.9920 38.95807   6      Conifer sites_sf <- st_as_sf(sites_xy,coords=c(\"X\",\"Y\")) head(sites_sf) #> Simple feature collection with 6 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -106.9934 ymin: 38.95807 xmax: -106.9898 ymax: 38.96237 #> CRS:           NA #>   fid         Name                   geometry #> 1   1        Rocky POINT (-106.9904 38.96237) #> 2   2        Aspen POINT (-106.9898 38.96222) #> 3   3         Road POINT (-106.9903 38.96083) #> 4   4   BeaverPond POINT (-106.9934 38.96006) #> 5   5 GrassyMeadow POINT (-106.9927 38.96023) #> 6   6      Conifer  POINT (-106.992 38.95807) st_crs(sites_sf) <- \"EPSG:4326\" sites_sf #> Simple feature collection with 9 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -106.9934 ymin: 38.95576 xmax: -106.9839 ymax: 38.96237 #> Geodetic CRS:  WGS 84 #>   fid           Name                   geometry #> 1   1          Rocky POINT (-106.9904 38.96237) #> 2   2          Aspen POINT (-106.9898 38.96222) #> 3   3           Road POINT (-106.9903 38.96083) #> 4   4     BeaverPond POINT (-106.9934 38.96006) #> 5   5   GrassyMeadow POINT (-106.9927 38.96023) #> 6   6        Conifer  POINT (-106.992 38.95807) #> 7   7 WeatherStation POINT (-106.9859 38.95641) #> 8   8        Smelter POINT (-106.9839 38.95576) #> 9   9     Roundabout  POINT (-106.988 38.95808) plet(vect(sites_sf),tiles=\"Streets\",col=\"red\")"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"geojson-and-geopackage-files","dir":"Articles","previous_headings":"Reading in spatial data on field sites.","what":"GeoJSON and GeoPackage files","title":"Sampling SDP Data Products at Field Sites","text":"Reading coordinates .csv text files works great point data, becomes cumbersome ’ve got data complicated geometries lines polygons. cases usually want read data format explicitly designed spatial information. two open data formats widespread use: geoJSON, open plain-text data format works really well small medium-sized datasets (hundred MB). GeoPackage, open geospatial database format based SQLITE can efficiently store larger complex datasets geoJSON, including related tables layers multiple geometry types. formats can read R using st_read() function sf package: Since reading geospatial format already spatial reference information, don’t need assign EPSG code. Similarly, GeoPackage: Although examples reading data directly web source, function works just well local files substituting path file.","code":"sites_gj <- st_read(\"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/rSDP_example_points_latlon.geojson\") #> Reading layer `rSDP_example_points_latlon' from data source  #>   `https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/rSDP_example_points_latlon.geojson'  #>   using driver `GeoJSON' #> Simple feature collection with 9 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -106.9934 ymin: 38.95576 xmax: -106.9839 ymax: 38.96237 #> Geodetic CRS:  WGS 84 sites_gp <- st_read(\"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/rSDP_example_points_latlon.gpkg\") #> Reading layer `rsdp_example_points_latlon' from data source  #>   `https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/rSDP_example_points_latlon.gpkg'  #>   using driver `GPKG' #> Simple feature collection with 9 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -106.9934 ymin: 38.95576 xmax: -106.9839 ymax: 38.96237 #> Geodetic CRS:  WGS 84"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"esri-shapefiles","dir":"Articles","previous_headings":"Reading in spatial data on field sites.","what":"ESRI Shapefiles","title":"Sampling SDP Data Products at Field Sites","text":"Shapefiles file format commonly used GIS software suite ArcGIS. Although important limitations, still common way share geographic data. files can also read R using st_read(). shapefiles actually collection related files, need download locally first loading.","code":"## Downloads files to a temporary directory. URL <- \"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/rSDP_example_points_latlon.shp.zip\" cur_tempfile <- tempfile() download.file(url = URL, destfile = cur_tempfile) out_directory <- tempfile() unzip(cur_tempfile, exdir = out_directory)  ## Loads into R. sites_shp <- st_read(dsn = out_directory) #> Reading layer `rSDP_example_points_latlon' from data source  #>   `/private/var/folders/yb/cc222hs54cg4ncd3_k6n9sn00000gn/T/Rtmp2FruyG/filef63d6dc03769'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 9 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -106.9934 ymin: 38.95576 xmax: -106.9839 ymax: 38.96237 #> Geodetic CRS:  WGS 84"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"finding-and-loading-sdp-data-products","dir":"Articles","previous_headings":"","what":"Finding and loading SDP data products","title":"Sampling SDP Data Products at Field Sites","text":"rSDP package designed simply data access catalog curated spatial data products. can access catalog like : Running function default arguments returns entire catalog, can also subset spatial domain, product type, data release.","code":"cat <- sdp_get_catalog() cat_snow <- sdp_get_catalog(types=c(\"Snow\"),                             releases=c(\"Release4\")) cat_snow[,1:6] #>     CatalogID  Release Type #> 75     R4D001 Release4 Snow #> 76     R4D002 Release4 Snow #> 77     R4D003 Release4 Snow #> 125    R4D051 Release4 Snow #> 126    R4D052 Release4 Snow #> 127    R4D053 Release4 Snow #> 128    R4D054 Release4 Snow #> 129    R4D055 Release4 Snow #> 130    R4D056 Release4 Snow #> 131    R4D057 Release4 Snow #> 132    R4D058 Release4 Snow #> 133    R4D059 Release4 Snow #> 134    R4D060 Release4 Snow #> 135    R4D061 Release4 Snow #> 136    R4D062 Release4 Snow #> 137    R4D063 Release4 Snow #> 138    R4D064 Release4 Snow #>                                                                              Product #> 75                                Snowpack Persistence Day of Year Yearly Timeseries #> 76                                      Snowpack Onset Day of Year Yearly Timeseries #> 77                                               Snowpack Duration Yearly Timeseries #> 125              Snowpack Proportional Reduction in Freezing Degree Days (2002-2021) #> 126 Snowpack Proportional Reduction in Early Season Freezing Degree Days (2002-2021) #> 127  Snowpack Proportional Reduction in Late Season Freezing Degree Days (2002-2021) #> 128               Snowpack Proportional Reduction in Growing Degree Days (2002-2021) #> 129  Snowpack Proportional Reduction in Early Season Growing Degree Days (2002-2021) #> 130   Snowpack Proportional Reduction in Late Season Growing Degree Days (2002-2021) #> 131                                  Snowpack Duration Mean (Water Year 1993 - 2022) #> 132                    Snowpack Duration Standard Deviation (Water Year 1993 - 2022) #> 133                                    Snowpack Onset Day of Year Mean (1993 - 2022) #> 134                        Snowpack Onset Day of Year Standard Deviation (1993-2022) #> 135                              Snowpack Persistence Day of Year Mean (1993 - 2022) #> 136                  Snowpack Persistence Day of Year Standard Deviation (1993-2022) #> 137                               Snowpack Persistence Uncertainty Yearly Timeseries #> 138                                     Snowpack Onset Uncertainty Yearly Timeseries #>     Domain Resolution #> 75      UG        27m #> 76      UG        27m #> 77      UG        27m #> 125     UG        27m #> 126     UG        27m #> 127     UG        27m #> 128     UG        27m #> 129     UG        27m #> 130     UG        27m #> 131     UG        27m #> 132     UG        27m #> 133     UG        27m #> 134     UG        27m #> 135     UG        27m #> 136     UG        27m #> 137     UG        27m #> 138     UG        27m"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"single-layer-data","dir":"Articles","previous_headings":"Finding and loading SDP data products","what":"Single layer data","title":"Sampling SDP Data Products at Field Sites","text":"datasets catalog represent data single period time summaries time-series datasets. example, want return single-layer snow data, can like : ’ve identified product interest, can load R using sdp_get_raster(): can confirm single layer dataset checking number layers using nlyr() function terra: wanted learn bit dataset? example, units snow duration? can look basic metadata SDP datasets catalog want detailed geospatial metadata, can retrieve full metadata dataset using sdp_get_metadata() can also plot dataset web map:","code":"cat_snow_single <- sdp_get_catalog(types=c(\"Snow\"),                                    releases=c(\"Release4\"),                                    timeseries_type=\"Single\") cat_snow_single[,1:6] #>     CatalogID  Release Type #> 125    R4D051 Release4 Snow #> 126    R4D052 Release4 Snow #> 127    R4D053 Release4 Snow #> 128    R4D054 Release4 Snow #> 129    R4D055 Release4 Snow #> 130    R4D056 Release4 Snow #> 131    R4D057 Release4 Snow #> 132    R4D058 Release4 Snow #> 133    R4D059 Release4 Snow #> 134    R4D060 Release4 Snow #> 135    R4D061 Release4 Snow #> 136    R4D062 Release4 Snow #>                                                                              Product #> 125              Snowpack Proportional Reduction in Freezing Degree Days (2002-2021) #> 126 Snowpack Proportional Reduction in Early Season Freezing Degree Days (2002-2021) #> 127  Snowpack Proportional Reduction in Late Season Freezing Degree Days (2002-2021) #> 128               Snowpack Proportional Reduction in Growing Degree Days (2002-2021) #> 129  Snowpack Proportional Reduction in Early Season Growing Degree Days (2002-2021) #> 130   Snowpack Proportional Reduction in Late Season Growing Degree Days (2002-2021) #> 131                                  Snowpack Duration Mean (Water Year 1993 - 2022) #> 132                    Snowpack Duration Standard Deviation (Water Year 1993 - 2022) #> 133                                    Snowpack Onset Day of Year Mean (1993 - 2022) #> 134                        Snowpack Onset Day of Year Standard Deviation (1993-2022) #> 135                              Snowpack Persistence Day of Year Mean (1993 - 2022) #> 136                  Snowpack Persistence Day of Year Standard Deviation (1993-2022) #>     Domain Resolution #> 125     UG        27m #> 126     UG        27m #> 127     UG        27m #> 128     UG        27m #> 129     UG        27m #> 130     UG        27m #> 131     UG        27m #> 132     UG        27m #> 133     UG        27m #> 134     UG        27m #> 135     UG        27m #> 136     UG        27m snow_persist_mean <- sdp_get_raster(catalog_id=\"R4D061\") snow_persist_mean #> class       : SpatRaster  #> dimensions  : 2689, 3075, 1  (nrow, ncol, nlyr) #> resolution  : 27, 27  (x, y) #> extent      : 305073, 388098, 4256064, 4328667  (xmin, xmax, ymin, ymax) #> coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613)  #> source      : UG_snow_persistence_mean_1993_2022_27m_v1.tif  #> name        : UG_snow_persistence_mean_1993_2022_27m_v1  #> min value   :                                   50.1529  #> max value   :                                  208.7463 nlyr(snow_persist_mean) #> [1] 1 cat_line <- dplyr::filter(cat_snow_single,CatalogID==\"R4D062\") cat_line$DataUnit #> [1] \"day of year\" snow_persist_meta <- sdp_get_metadata(\"R4D062\") print(snow_persist_meta$qgis$abstract) #> [[1]] #> [1] \"This dataset represents an estimate of interannual variability in the day of year (i.e. ,  \\\"Julian Day\\\") of the persistence of the seasonal snowpack.  Specifically these are estimates of the first day of bare ground derived from long-term time-series of Landsat TM,  ETM,  and OLI imagery starting in 1993.  These maps combine monthly ground snow cover fraction maps from the USGS Landsat Collection 2 Level 3 fSCA Statistics (https://doi.org/10.5066/F7VQ31ZQ) with a time-series analysis of a spectral snow index (NDSI) using a heirarchical Bayesian model (Gao et al.  2021).  The combination of these two approaches allows reconstruction of detailed annual snow persistence maps from sparse imagery time-series (Landsat data have an 8 to 16-day return interval in the absence of clouds).\\n\\nA comparison of these data to independent in-situ observations from SNOTEL and microclimate sensors show that these products capture about 85% of spatial variation in snow persistence for recent years (2021-2022),  and greater than 90% of temporal variation across the full 1993 - 2022 time-series.\\n\\nThis data represents the standard deviation of annual estimates from 1993 - 2022.\\n\\nReferences: \\n\\nGao, X., Gray, J. M., & Reich, B. J. (2021). Long-term, medium spatial resolution annual land surface phenology with a Bayesian hierarchical model. Remote Sensing of Environment, 261, 112484. https://doi.org/10.1016/j.rse.2021.112484 \" plet(snow_persist_mean,tiles=\"Streets\",      main=\"Snowpack Persistence \\n (day of year)\")"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"raster-time-series","dir":"Articles","previous_headings":"Finding and loading SDP data products","what":"Raster time-series","title":"Sampling SDP Data Products at Field Sites","text":"Rather representing single layer data, SDP data products delivered time-series, multiple related maps representing data daily, monthly, yearly intervals. Connecting datasets identical single-layer data, returned object multiple layers. example, connect dataset representing yearly time-series snowpack persistence: default yearly time-series return years available data. Alternatively, can return subset years specifying years argument: keep track layers represent time intervals, can look name layer:","code":"cat_snow_yearly <- sdp_get_catalog(types=c(\"Snow\"),                                    releases=c(\"Release4\"),                                    timeseries_type=\"Yearly\") snow_persist_yearly <- sdp_get_raster(\"R4D001\") #> [1] \"Returning yearly dataset with 30 layers...\" snow_persist_recent <- sdp_get_raster(\"R4D001\",years=c(2018:2022)) #> [1] \"Returning yearly dataset with 5 layers...\" snow_persist_recent #> class       : SpatRaster  #> dimensions  : 2689, 3075, 5  (nrow, ncol, nlyr) #> resolution  : 27, 27  (x, y) #> extent      : 305073, 388098, 4256064, 4328667  (xmin, xmax, ymin, ymax) #> coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613)  #> sources     : UG_snow_persistence_year_2018_27m_v1.tif   #>               UG_snow_persistence_year_2019_27m_v1.tif   #>               UG_snow_persistence_year_2020_27m_v1.tif   #>               ... and 2 more source(s) #> names       :      2018,     2019,      2020,      2021,      2022  #> min values  :  27.22007,  79.9462,  48.37198,  39.40033,  24.77002  #> max values  : 202.39381, 211.7621, 214.12854, 199.10818, 192.94231 names(snow_persist_recent) #> [1] \"2018\" \"2019\" \"2020\" \"2021\" \"2022\""},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"basic-plotting","dir":"Articles","previous_headings":"Finding and loading SDP data products","what":"Basic plotting","title":"Sampling SDP Data Products at Field Sites","text":"can plot subset layers web map like : plots resampled, lower resolution version two layers.","code":"plet(snow_persist_recent, c(\"2018\",\"2019\"),      tiles=\"Streets\",shared=TRUE,collapse=FALSE)"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"extracting-data-at-field-sites","dir":"Articles","previous_headings":"","what":"Extracting data at field sites","title":"Sampling SDP Data Products at Field Sites","text":"Now field site data raster data products loaded R, almost ready sample values products field sites. one last step, however.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"re-projecting-field-site-data","dir":"Articles","previous_headings":"Extracting data at field sites","what":"Re-projecting field site data","title":"Sampling SDP Data Products at Field Sites","text":"field site data spatial data products different coordinate systems, need “re-project” field site data match coordinate system raster data. can using st_transform() function sf package. coordinate systems transformations, see article “Wrangling Spatial Data”.","code":"sites_proj <- vect(st_transform(sites_sf,crs=crs(snow_persist_recent))) crs(sites_proj)==crs(snow_persist_recent) #> [1] TRUE"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"simple-extraction-at-points","dir":"Articles","previous_headings":"Extracting data at field sites","what":"Simple extraction at points","title":"Sampling SDP Data Products at Field Sites","text":"Now ’ve got field site data raster data products coordinate system, ready summarize values products sites. using function sdp_extract_data(). simplest case, want get values raster cells overlap locations points. can like : first two arguments sdp_extract_data() function spatial data product sample field site locations. Specifying method='Simple returns raw raster values without interpolation. alternative, can also extract interpolated values, values summarize values cells surrounding point. Since research sites rarely fall exact center raster cells, can sometimes yield better estimates: Comparing interpolated values simple extracted values, see choice make bit difference: much extraction method matters depends spatial resolution source data variable across space. general, method matters coarser resolution datasets.","code":"snow_sample_simple <- sdp_extract_data(snow_persist_recent,sites_proj,                                        method=\"simple\") #> [1] \"Extracting data at 9 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_sample_simple$method <- \"simple\" head(snow_sample_simple) #>   fid         Name ID     2018     2019     2020     2021     2022 method #> 1   1        Rocky  1 119.2039 152.5670 130.0222 127.3905 128.5814 simple #> 2   2        Aspen  2 124.7617 158.4428 134.5020 133.2598 133.5708 simple #> 3   3         Road  3 124.4804 158.8267 135.0165 132.9169 134.0559 simple #> 4   4   BeaverPond  4 125.8458 159.4807 136.3522 134.9364 136.2159 simple #> 5   5 GrassyMeadow  5 127.4351 159.4083 137.0675 136.6312 137.2897 simple #> 6   6      Conifer  6 122.9492 150.5847 133.7281 132.7448 134.1880 simple snow_sample_bilin <- sdp_extract_data(snow_persist_recent,sites_proj,method=\"bilinear\") #> [1] \"Extracting data at 9 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_sample_bilin$method <- \"bilinear\" library(tidyr) #> Warning: package 'tidyr' was built under R version 4.1.2 #>  #> Attaching package: 'tidyr' #> The following object is masked from 'package:terra': #>  #>     extract library(ggplot2) #> Warning: package 'ggplot2' was built under R version 4.1.2 snow_sample <- as.data.frame(rbind(snow_sample_simple,                                     snow_sample_bilin)) snow_long <- pivot_longer(snow_sample,cols=contains(\"X\"),                           names_to=\"year\",values_to=\"snow_persist_doy\") snow_wide <- pivot_wider(snow_long,names_from=\"method\",                          values_from=\"snow_persist_doy\") snow_wide$year <- gsub(\"X\",\"\",snow_wide$year)  ggplot(snow_wide) +   geom_point(aes(x = bilinear, y = simple, color = Name, shape = year)) +   scale_x_continuous(\"Snow Persistence (bilinear interpolation)\") +   scale_y_continuous(\"Snow Persistence (simple extraction)\") +   theme_bw()"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"buffered-extraction-at-points-with-summaries","dir":"Articles","previous_headings":"Extracting data at field sites","what":"Buffered extraction at points with summaries","title":"Sampling SDP Data Products at Field Sites","text":"example extracts data exact locations points. want get sense datasets vary landscape surrounding points? case need create new polygon dataset covers areas within certain distance points. can accomplish using st_buffer() function sf package: } code creates circular polygons centered point radius 100m. can examine results plotting original points buffers web map: grey shaded areas covered buffered polygons. can now use polygons extract raster values covered polygon areas. Since multiple raster cells fall within polygon, need specify function use summarize values cells polygon. default compute mean value , can also specify R function takes vector input returns single value. example, compute mean, minimum, maximum well 25th 75th percentiles snow persistence buffered areas: Now extracted data, can reshape visualization. code binds rows extracted data together reshapes using pivot_longer pivot_wider functions (tidyr package) different summaries represented different variables. can plot summaries spatial variability snow persistence across sites years: Spatial variability spring snowpack persistence 2018 2022. thin lines span range minimum maximum values within 100 m field sites, thick lines represent range 25th 75th percentile. open circles represent mean. can see sites melt seasonal snowpack predictable sequence, “Rocky”, “Road”, “Aspen” sites usually first melt, others usually later. can also see tremendous variability years, sites 2018 melting 3 weeks earlier 2019. can also see late-melting year (2019) shows reduced variability melt timing landscape surrounding sites. evident smaller range minimum maximum values well reduced variability sites.","code":"sites_buff100 <- st_buffer(st_as_sf(sites_proj),dist=100) plet(vect(sites_buff100),tiles=\"Streets\",      col=\"grey20\",alpha=0.2) |>   points(sites_proj,col=\"black\") snow_sample_mean <- sdp_extract_data(snow_persist_recent,                                      vect(sites_buff100)) #> [1] \"Extracting data at 9 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_sample_mean$stat <- \"mean\" snow_sample_min <- sdp_extract_data(snow_persist_recent,                                     vect(sites_buff100),                                     sum_fun=\"min\") #> [1] \"Extracting data at 9 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_sample_min$stat <- \"min\" snow_sample_q25 <- sdp_extract_data(snow_persist_recent,                                     vect(sites_buff100),                                     sum_fun=function(x) quantile(x,probs=c(0.25))) #> [1] \"Extracting data at 9 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_sample_q25$stat <- \"q25\" snow_sample_q75 <- sdp_extract_data(snow_persist_recent,                                     vect(sites_buff100),                                     sum_fun=function(x) quantile(x,probs=c(0.75))) #> [1] \"Extracting data at 9 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_sample_q75$stat <- \"q75\" snow_sample_max <- sdp_extract_data(snow_persist_recent,                                     vect(sites_buff100),                                     sum_fun=\"max\") #> [1] \"Extracting data at 9 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_sample_max$stat <- \"max\" snow_sample_stats <- as.data.frame(rbind(snow_sample_min,                            snow_sample_q25,                            snow_sample_mean,                            snow_sample_q75,                            snow_sample_max)) snow_stats_long <- pivot_longer(snow_sample_stats,cols=contains(\"X\"),                                 names_to=\"year\",values_to=\"snow_persist_doy\") snow_stats_wide <- pivot_wider(snow_stats_long,names_from=\"stat\",                                values_from=\"snow_persist_doy\") snow_stats_wide$year <- gsub(\"X\",\"\",snow_stats_wide$year) head(snow_stats_wide) #> # A tibble: 6 × 9 #>     fid Name     ID year    min   q25  mean   q75   max #>   <int> <chr> <dbl> <chr> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1     1 Rocky     1 2018   113.  117.  120.  124.  128. #> 2     1 Rocky     1 2019   150.  153.  155.  156.  160. #> 3     1 Rocky     1 2020   127.  129.  131.  134.  138. #> 4     1 Rocky     1 2021   122.  126.  129.  133.  137. #> 5     1 Rocky     1 2022   124.  127.  130.  133.  137. #> 6     2 Aspen     2 2018   113.  117.  121.  124.  128. library(ggplot2) ggplot(snow_stats_wide)+   geom_linerange(aes(x=Name,ymin=min,ymax=max,color=year),                  linewidth=0.5,position=position_dodge(width=0.5))+   geom_linerange(aes(x=Name,ymin=q25,ymax=q75,color=year),                  linewidth=1.5,position=position_dodge(width=0.5))+   geom_point(aes(x=Name,y=mean,fill=year), shape=21, color=\"black\",size=1.5,              position=position_dodge(width=0.5))+   scale_y_continuous(\"Spring Snowpack Persistence (Day of Year)\")+   scale_x_discrete(\"Site\")+   theme_bw()"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"extracting-summaries-using-lines-and-polygons","dir":"Articles","previous_headings":"Extracting data at field sites","what":"Extracting summaries using lines and polygons","title":"Sampling SDP Data Products at Field Sites","text":"example creates polygons buffering field sites represented points, can also summarise data products using polygon vector data. example reads polygon representing Gothic Townsite area computes summaries snow dissapearance across entire polygon:","code":"## Reads in polygons gt_poly <- vect(st_read(\"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/GT_region_vect_1m.geojson\")) #> Reading layer `GT_region_vect_1m' from data source  #>   `https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/GT_region_vect_1m.geojson'  #>   using driver `GeoJSON' #> Simple feature collection with 1 feature and 2 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: 327105 ymin: 4313359 xmax: 328312 ymax: 4314793 #> Projected CRS: WGS 84 / UTM zone 13N  ## Extracts summaries snow_gt_mean <- sdp_extract_data(snow_persist_recent,gt_poly) #> [1] \"Extracting data at 1 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_gt_mean$stat <- \"mean\" snow_gt_min <- sdp_extract_data(snow_persist_recent,gt_poly,                                     sum_fun=\"min\") #> [1] \"Extracting data at 1 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_gt_min$stat <- \"min\" snow_gt_q10 <- sdp_extract_data(snow_persist_recent,gt_poly,                                     sum_fun=function(x) quantile(x,probs=c(0.1))) #> [1] \"Extracting data at 1 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_gt_q10$stat <- \"q10\" snow_gt_q90 <- sdp_extract_data(snow_persist_recent,gt_poly,                                     sum_fun=function(x) quantile(x,probs=c(0.9))) #> [1] \"Extracting data at 1 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_gt_q90$stat <- \"q90\" snow_gt_max <- sdp_extract_data(snow_persist_recent,gt_poly,                                     sum_fun=\"max\") #> [1] \"Extracting data at 1 locations for 5 raster layers.\" #> [1] \"Extraction complete.\" snow_gt_max$stat <- \"max\"  ## Binds output together snow_gt_stats <- as.data.frame(rbind(snow_gt_min,                                     snow_gt_q10,                                     snow_gt_mean,                                     snow_gt_q90,                                     snow_gt_max))  ## Reshapes for plotting. snow_gt_long <- tidyr::pivot_longer(snow_gt_stats,cols=contains(\"X\"),                                 names_to=\"year\",values_to=\"snow_persist_doy\") snow_gt_wide <- tidyr::pivot_wider(snow_gt_long,names_from=\"stat\",values_from=\"snow_persist_doy\") snow_gt_wide$year <- gsub(\"X\",\"\",snow_gt_wide$year)  ## Plots variability. ggplot(snow_gt_wide)+   geom_linerange(aes(x=year,ymin=min,ymax=max,color=year),                  linewidth=0.5,position=position_dodge(width=0.5))+   geom_linerange(aes(x=year,ymin=q10,ymax=q90,color=year),                  linewidth=1.5,position=position_dodge(width=0.5))+   geom_point(aes(x=year,y=mean,fill=year), shape=21, color=\"black\",size=1.5,              position=position_dodge(width=0.5))+   scale_y_continuous(\"Spring Snowpack Persistence (Day of Year)\")+   scale_x_discrete(\"year\")+   theme_bw()"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"summarising-categorical-data-products","dir":"Articles","previous_headings":"Extracting data at field sites","what":"Summarising categorical data products","title":"Sampling SDP Data Products at Field Sites","text":"strategies work well summarising data products represent continuous numeric values, categorical rasters land cover maps pose additional challenge. summary functions make sense continuous data (e.g. mean, median, max) make sense categorical data. example, can load landcover map vicinity Gothic Townsite polygon loaded . want estimate proportion study area covered landcover class? case, want extract raster values within polygon summarise . can accomplish using combination sdp_extract_data() function along group_by() summarise() functions dplyr package: specify sum_fun=NULL sdp_extract_data() function , function returns data frame (~1.1 million) cell values intersect polygon. specifying weights=TRUE also return proportion raster cell covered polygon. cells along boundary polygon partially covered, weight resulting data less one. Now can summarise values landcover class: Now ’ve got estimate area proportion landcover class polygon. classes numeric codes, can match names landcover classes metadata: Success! Although example uses single polygon, similar workflow work datasets contain multiple polygons well line data.","code":"ug_lc <- sdp_get_raster(\"R3D018\") lc_crop <- crop(ug_lc,st_bbox(gt_poly))  plot(lc_crop,main=\"Gothic Landcover\") plot(gt_poly,add=TRUE) gt_lc_all <- sdp_extract_data(lc_crop,gt_poly,bind=FALSE,return_type=\"DataFrame\",                               sum_fun=NULL,weights=TRUE) #> [1] \"Extracting data at 1 locations for 1 raster layers.\" #>  |---------|---------|---------|---------| =========================================                                            [1] \"Extraction complete.\" str(gt_lc_all) #> 'data.frame':    1119828 obs. of  3 variables: #>  $ ID                : num  1 1 1 1 1 1 1 1 1 1 ... #>  $ UG_landcover_1m_v4: num  2 2 2 2 2 2 2 2 2 2 ... #>  $ weight            : num  1 1 1 1 1 ... library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:terra': #>  #>     intersect, union #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union gt_area <- st_area(st_as_sf(gt_poly)) cell_size <- res(lc_crop)  gt_lc_sum <- gt_lc_all %>%              group_by(UG_landcover_1m_v4) %>%              summarise(n_cells=sum(weight),                       covertype_area=n_cells*cell_size[1],                       covertype_prop=covertype_area/gt_area) gt_lc_sum #> # A tibble: 10 × 4 #>    UG_landcover_1m_v4 n_cells covertype_area covertype_prop #>                 <dbl>   <dbl>          <dbl>        [1/m^2] #>  1                  1 166899.        166899.       0.149    #>  2                  2 265807.        265807.       0.237    #>  3                  3 502699.        502699.       0.449    #>  4                  4  13624.         13624.       0.0122   #>  5                  6  20291.         20291.       0.0181   #>  6                  7   6283.          6283.       0.00561  #>  7                  8    269.           269.       0.000240 #>  8                 10 113793.        113793.       0.102    #>  9                 11   8944.          8944.       0.00799  #> 10                 12  21219.         21219.       0.0189 lc_meta <- sdp_get_metadata(\"R3D018\") lc_codes <- 1:12 lc_classes<- c(\"evergreen trees and shrubs\",              \"deciduous trees greater than 2m tall\",              \"meadow, grassland and subshrub\",              \"persistent open water\",               \"persistent snow and ice\",              \"rock, bare soil, and sparse vegetation\",              \"building or structure\",               \"paved or other impervious surface\",              \"irrigated pasture and other cultivated lands\",              \"deciduous shrubs up to 2m tall\",              \"evergreen forest understory and small gap\",              \"deciduous forest understory and small gap\") lc_df <- data.frame(UG_landcover_1m_v4=lc_codes,                     class_name=lc_classes) gt_lc_names <- left_join(gt_lc_sum,lc_df,by=\"UG_landcover_1m_v4\") gt_lc_names[,-1] #> # A tibble: 10 × 4 #>    n_cells covertype_area covertype_prop class_name                              #>      <dbl>          <dbl>        [1/m^2] <chr>                                   #>  1 166899.        166899.       0.149    evergreen trees and shrubs              #>  2 265807.        265807.       0.237    deciduous trees greater than 2m tall    #>  3 502699.        502699.       0.449    meadow, grassland and subshrub          #>  4  13624.         13624.       0.0122   persistent open water                   #>  5  20291.         20291.       0.0181   rock, bare soil, and sparse vegetation  #>  6   6283.          6283.       0.00561  building or structure                   #>  7    269.           269.       0.000240 paved or other impervious surface       #>  8 113793.        113793.       0.102    deciduous shrubs up to 2m tall          #>  9   8944.          8944.       0.00799  evergreen forest understory and small … #> 10  21219.         21219.       0.0189   deciduous forest understory and small …"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"strategies-for-boosting-performance","dir":"Articles","previous_headings":"","what":"Strategies for boosting performance","title":"Sampling SDP Data Products at Field Sites","text":"examples , limited amount data need download locally connecting data products stored cloud. many use cases, great, sometimes operations can quite slow, often limited speed internet connection. strategies speeding extracting data large rasters, rasters lots layers, / large numbers field sites:","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"downloading-raster-data-locally","dir":"Articles","previous_headings":"Strategies for boosting performance","what":"Downloading raster data locally","title":"Sampling SDP Data Products at Field Sites","text":"default behavior sdp_get_raster() connect cloud-based data source without downloading file(s) locally. extraction operation prohibitively slow, sometimes makes sense download files locally running sdp_extract_data(). download files, need specify download_files=TRUE local file path storing files: default argument overwrite=FALSE function download files layers don’t already exist local filesystem create SpatRaster object linked local datasource instead cloud. files already exist locally, files downloaded. means initial download step, subsequent calls sdp_get_raster() reference files (subsets files) result additional downloads. Specifying overwrite=TRUE cause datasets re-downloaded time function run. can look speedup conferred local downloads large extraction operations. function spatSample() terra package generates (potentially large) random regular samples raster cells. use function compare speed extractions cloud-based local datasets: datasets already exist locally, operation much faster. Obviously doesn’t take consideration amount time takes download files initially.","code":"snow_persist_local <- sdp_get_raster(\"R4D001\", years = c(2018:2022), download_files = TRUE,                                      download_path = \"~/Downloads\",overwrite=FALSE) #> [1] \"Returning yearly dataset with 5 layers...\" #> [1] \"All files exist locally. Specify `overwrite=TRUE` to overwrite existing files.\" #> [1] \"Loading raster from local paths.\" # Cloud-based dataset start <- Sys.time() sample_cloud <- spatSample(snow_persist_recent,size=100,method=\"random\") Sys.time() - start #> Time difference of 41.10631 secs  # Local dataset. start <- Sys.time() sample_local <- spatSample(snow_persist_local,size=100,method=\"random\") Sys.time() - start #> Time difference of 0.440625 secs"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"crop-then-extract","dir":"Articles","previous_headings":"Strategies for boosting performance","what":"Crop then extract","title":"Sampling SDP Data Products at Field Sites","text":"Another strategy effective sites sample extract data cover small portion extent full raster. case, can efficient crop raster extent sites performing extraction. Cropping cloud-based dataset download cropped subset data desired. example strategy, generate large number random points within boundary Gothic Townsite polygon loaded earlier, crop large elevation dataset extent raster. much smaller cropped dataset now stored memory locally, now subsequent operations fast.","code":"gt_pts <- spatSample(gt_poly,size=1000) dem <- sdp_get_raster(\"R3D008\") dem_crop <- crop(dem,gt_pts) ncell(dem_crop) #> [1] 1616643 c(\"ncells_full\"=ncell(dem),\"ncells_cropped\"=ncell(dem_crop)) #>    ncells_full ncells_cropped  #>     6026339412        1616643 start <- Sys.time() elev_extract_full <- sdp_extract_data(dem,locations=gt_pts) #> [1] \"Extracting data at 1000 locations for 1 raster layers.\" #> [1] \"Extraction complete.\" Sys.time() - start #> Time difference of 6.519675 secs  start <- Sys.time() elev_extract_cropped <- sdp_extract_data(dem_crop,locations=gt_pts) #> [1] \"Extracting data at 1000 locations for 1 raster layers.\" #> [1] \"Extraction complete.\" Sys.time() - start #> Time difference of 0.01676106 secs"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/field-site-sampling.html","id":"parallel-processing","dir":"Articles","previous_headings":"Strategies for boosting performance","what":"Parallel processing","title":"Sampling SDP Data Products at Field Sites","text":"extraction operations get data large number layers (daily climate time-series), can make sense extraction parallel across multiple R processes. foreach doParallel packages provide facilities setting kind parallel process. core workflow call function foreach, similar standard loop, allows different iterations loop sent independent R processes. complication parallel processing use case ’s currently possible pass SpatVector SpatRaster objects parent R process parallel worker processes. means need create separate SpatRaster objects subsets data processed parallel. ’s example parallel extraction daily air temperature time-series small number research sites worked earlier: Finally can reshape data visualization. sites within hundred meters differences microclimate mostly due vegetation structure solar radiation.","code":"library(foreach) library(doParallel) #> Loading required package: iterators #> Loading required package: parallel  ## Can't pass SpatVector or SpatRaster objects via Foreach, so convert to sf. locations_sf <- st_as_sf(sites_proj)  ## Sets the number of parallel processes. n_workers <- 4  start <- Sys.time() cl <- makeCluster(n_workers) registerDoParallel(cl) days <- seq(as.Date(\"2016-10-01\"),as.Date(\"2022-9-30\"), by=\"month\")  extr_list <- foreach(i=1:length(days),.packages=c(\"terra\",\"rSDP\",\"sf\")) %dopar% {   tmax <- sdp_get_raster(\"R4D007\",date_start=days[i],                          date_end=days[i],verbose=FALSE)    locations_sv <- vect(locations_sf)    extr_dat <- sdp_extract_data(tmax,locations=locations_sv,                                 verbose=FALSE,return_type=\"sf\")[,4]    (st_drop_geometry(extr_dat)) } stopCluster(cl) tmax_extr <- cbind(locations_sf,                    do.call(cbind,extr_list)) elapsed <- Sys.time() - start elapsed #> Time difference of 43.39494 secs tmax_extr_long <- pivot_longer(tmax_extr,cols=contains(\"X\"),                                       values_to=\"average_tmax\",                                       names_to=\"year_month\") tmax_extr_long$date <- as.Date(paste0(gsub(\"X\",\"\",tmax_extr_long$year_month),\".15\"),                                format=\"%Y.%m.%d\")  ggplot(tmax_extr_long)+   geom_line(aes(x=date,y=average_tmax,color=Name))+   scale_y_continuous(\"Average Monthly Tmax (C)\")+   theme_bw()"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"workspace-setup","dir":"Articles","previous_headings":"","what":"Workspace setup","title":"Visualizing Raster Data","text":"First need install load packages. addition packages required rSDP, need install others well.","code":"#install.packages(c(\"tidyterra\",\"ggspatial\",\"ggplot2\",\"gridExtra)) #remotes::install_github(\"rmbl-sdp/rSDP\") #remotes::install_github(\"rstudio/leaflet\")  library(sf) library(terra) library(leaflet) library(tidyterra) library(ggspatial) library(ggplot2) library(gridExtra) library(rSDP)"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"finding-sdp-data","dir":"Articles","previous_headings":"","what":"Finding SDP data","title":"Visualizing Raster Data","text":"First, use functions rSDP package locate download raster data. information finding connecting datasets, check tutorial “Accessing Cloud-based Datasets”.","code":"snow_cat <- sdp_get_catalog(domains=\"UG\",types=\"Snow\",releases=\"Release4\") snow_cat[,c(1,4)] #>     CatalogID #> 75     R4D001 #> 76     R4D002 #> 77     R4D003 #> 125    R4D051 #> 126    R4D052 #> 127    R4D053 #> 128    R4D054 #> 129    R4D055 #> 130    R4D056 #> 131    R4D057 #> 132    R4D058 #> 133    R4D059 #> 134    R4D060 #> 135    R4D061 #> 136    R4D062 #> 137    R4D063 #> 138    R4D064 #>                                                                              Product #> 75                                Snowpack Persistence Day of Year Yearly Timeseries #> 76                                      Snowpack Onset Day of Year Yearly Timeseries #> 77                                               Snowpack Duration Yearly Timeseries #> 125              Snowpack Proportional Reduction in Freezing Degree Days (2002-2021) #> 126 Snowpack Proportional Reduction in Early Season Freezing Degree Days (2002-2021) #> 127  Snowpack Proportional Reduction in Late Season Freezing Degree Days (2002-2021) #> 128               Snowpack Proportional Reduction in Growing Degree Days (2002-2021) #> 129  Snowpack Proportional Reduction in Early Season Growing Degree Days (2002-2021) #> 130   Snowpack Proportional Reduction in Late Season Growing Degree Days (2002-2021) #> 131                                  Snowpack Duration Mean (Water Year 1993 - 2022) #> 132                    Snowpack Duration Standard Deviation (Water Year 1993 - 2022) #> 133                                    Snowpack Onset Day of Year Mean (1993 - 2022) #> 134                        Snowpack Onset Day of Year Standard Deviation (1993-2022) #> 135                              Snowpack Persistence Day of Year Mean (1993 - 2022) #> 136                  Snowpack Persistence Day of Year Standard Deviation (1993-2022) #> 137                               Snowpack Persistence Uncertainty Yearly Timeseries #> 138                                     Snowpack Onset Uncertainty Yearly Timeseries"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"reading-in-data","dir":"Articles","previous_headings":"","what":"Reading in data","title":"Visualizing Raster Data","text":"","code":"snow_rast <- sdp_get_raster(\"R4D001\",years=2018:2021,                             download_files = TRUE, download_path = \"~/Downloads\") #> [1] \"Returning yearly dataset with 4 layers...\" #> [1] \"All files exist locally. Specify `overwrite=TRUE` to overwrite existing files.\" #> [1] \"Loading raster from local paths.\" roads <- st_read(\"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/UG_roads_trails_osm.geojson\") #> Reading layer `UG_roads_trails_osm' from data source  #>   `https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/UG_roads_trails_osm.geojson'  #>   using driver `GeoJSON' #> Simple feature collection with 6814 features and 10 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: -107.2097 ymin: 38.45493 xmax: -106.3205 ymax: 39.06456 #> Geodetic CRS:  WGS 84"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"formatting-data","dir":"Articles","previous_headings":"","what":"Formatting data","title":"Visualizing Raster Data","text":"’ve got data loaded, need things clean get right format plotting:","code":"##Pulls out major roads. roads_major <- filter(roads,highway %in% c(\"secondary\",\"trunk\"))  ##Converts to spatvector. roads_sv <- vect(roads_major)  ##Re-projects to coordinate system of raster. roads_proj <- project(roads_sv,crs(snow_rast))"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"basic-raster-maps-with-terraplot","dir":"Articles","previous_headings":"","what":"Basic raster maps with terra::plot()","title":"Visualizing Raster Data","text":"fastest way plot raster dataset R built-plot method SpatRaster datasets terra package. can simple :  generates plots layers raster dataset. case, plots represent snowpack persistence four years, 2018 2021. notice color ramp visualizing data different layer. might ideal layers share numeric scale. can standardize scales color ramp across layers specifying range argument:  default color ramp one possibility visualization. color scales viridis package particularly useful, color-blind friendly nice properties.  can define custom color ramp call colorRampPallette(). creates color generator function can use create arbitrary number colors along gradient. example , define jet_colors() function pass along col argument plot, creates color scale 255 values.  specifying color ramp, using mixture named colors (e.g. \"yellow\"), along 6-digit alphanumeric codes starting #. codes “hex colors”, widely used color coding system. look hex code color generate custom color ramps hex codes, check scale web resource. ’s color-blind friendly custom color ramp:","code":"plot(snow_rast) plot(snow_rast,range=c(50,220)) library(viridis) #> Warning: package 'viridisLite' was built under R version 4.1.2 plot(snow_rast,range=c(30,220),col=viridis::cividis(n=255)) jet_colors <-   colorRampPalette(c(\"#00007F\", \"blue\", \"#007FFF\", \"cyan\",                      \"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"))  plot(snow_rast[[1]],range=c(25,220),      col=rev(jet_colors(255)),      main=\"Snow Persistence (Day of Year)\") plot(roads_proj,add=TRUE,col=\"grey20\") earth_colors <-   colorRampPalette(c(\"#001344\", \"#002E68\", \"#095186\",                       \"#19769F\",\"#2F9AB1\", \"#47C7B8\",                       \"#63D9A9\", \"#82E7A1\",\"#A5F3A5\",                      \"#D8FACC\", \"#FAFFF5\"))  plot(snow_rast[[1]],range=c(25,220),      col=earth_colors(255),      main=\"Snow Persistence (Day of Year)\") plot(roads_proj,add=TRUE,col=\"grey20\")"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"web-maps-with-leaflet","dir":"Articles","previous_headings":"","what":"Web maps with leaflet","title":"Visualizing Raster Data","text":"’s sometimes useful plot raster datasets web map enables interactive exploration overlays data informative basemap. terra::plet() function achieves :","code":"map <- terra::plet(snow_rast[[1]],tiles=\"Streets\",col=rev(earth_colors(255))) lines(map,roads_proj,col=\"white\")"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"prettier-maps-with-tidyterra-and-ggplot2","dir":"Articles","previous_headings":"","what":"Prettier maps with tidyterra and ggplot2","title":"Visualizing Raster Data","text":"base functions terra plotting maps flexible fast, can often take quite bit coding customization achieve publication-quality result. alternative option use functions tidyterra package integrate raster vector datasets widely used ggplot2 plotting system. Integrating scale bar north arrow functions ggspatial package can achieve publication-quality visualizations without large amount customization: Just like plot types use ggplot, can change extent plot specifying scale limits:","code":"## Simple one-panel map with scalebar and north arrow. map0 <- ggplot()+   geom_spatraster(data=snow_rast[[1]])+   geom_spatvector(aes(color=\"highway\"),data=roads_proj)+   scale_color_manual(\"\",values=c(\"grey40\"))+   scale_fill_whitebox_c(\"Day of Year\",limits=c(20,220),                         palette=\"muted\",direction=1)+   scale_x_continuous(expand=c(0,0))+   scale_y_continuous(expand=c(0,0))+   annotation_scale(location=\"br\", height=unit(0.2,\"cm\"))+   annotation_north_arrow(location=\"bl\", height=unit(1,\"cm\"),                          width=unit(1,\"cm\"))+   theme_minimal() #> SpatRaster resampled to ncells = 501134 ## Zooming in. map0 + scale_x_continuous(limits=c(327306, 342195),expand=c(0,0))+        scale_y_continuous(limits=c(4289070, 4307572),expand=c(0,0))"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"faceting-for-multi-panel-maps","dir":"Articles","previous_headings":"","what":"Faceting for multi-panel maps","title":"Visualizing Raster Data","text":"One powerful features ggplot() ability display multiple subsets data small multiples, repeated plots common scales visual elements. called facets ggplot syntax. example , adding facet_wrap(facets=~lyr) basic plot produces multi-panel plot layer SpatRaster plotted separate panel common color scale:","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"simple-faceted-map","dir":"Articles","previous_headings":"Faceting for multi-panel maps","what":"Simple faceted map","title":"Visualizing Raster Data","text":"","code":"map1 <- ggplot()+   geom_spatraster(data=snow_rast[[1:3]])+   facet_wrap(facets=~lyr)+   theme_minimal() #> SpatRaster resampled to ncells = 501134 map1"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"color-ramps-with-tidyterra-and-viridis","dir":"Articles","previous_headings":"Faceting for multi-panel maps","what":"Color ramps with tidyterra and viridis","title":"Visualizing Raster Data","text":"tidyterra package comes useful color ramps, including Wikimedia scales topographic data (see scale_fill_wiki_* scale_color_wiki_* functions), well general Whitebox color ramps. can also use great scales viridis package:","code":"map1 <- ggplot()+   geom_spatraster(data=snow_rast[[1:3]])+   facet_wrap(facets=~lyr)+   scale_fill_viridis(\"Snow \\nPersistence \\n(DOY)\",option=\"mako\")+   theme_minimal() #> SpatRaster resampled to ncells = 501134 map1"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"full-faceted-map-with-scalebar","dir":"Articles","previous_headings":"Faceting for multi-panel maps","what":"Full faceted map with scalebar","title":"Visualizing Raster Data","text":"bit extra wrangling, can get publication quality multi-panel map ,ggplot2, tidyterra, ggspatial. code , create two tables parameters specify details scale bar north arrow panels appear.","code":"# Study area boundary (simplified for fast display). UG_bound <- sf::st_read(\"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/UG_region_vect_1m.geojson\") #> Reading layer `UG_region_vect_1m' from data source  #>   `https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/UG_region_vect_1m.geojson'  #>   using driver `GeoJSON' #> Simple feature collection with 1 feature and 2 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: 307895 ymin: 4258017 xmax: 385679 ymax: 4326087 #> Projected CRS: WGS 84 / UTM zone 13N UG_simple <- sf::st_simplify(UG_bound,dTolerance=100)  # North Arrow and Scale Bar properties. arrow_params <- tibble::tibble(   lyr = \"2020\",   location = \"br\")  scale_params <- tibble::tibble(   lyr = \"2018\",   location= \"br\",   width_hint=0.3,   line_col=\"white\",   text_col=\"white\")  # Full Map map2 <- ggplot()+   geom_spatraster(data=snow_rast[[1:3]],maxcell=5e+05)+   geom_spatvector(aes(color=\"Study Area\"),data=UG_simple,                   fill=rgb(0,0,0,0),lwd=0.5)+   labs(title=\"Spring Snow Persistence\",tag=\"(a)\")+   scale_fill_viridis(\"Day of Year\",option=\"mako\",limits=c(20,220))+   scale_color_manual(\"\",values=c(\"grey90\"))+   scale_x_continuous(expand=c(0,0),breaks=c(-107,-106.4))+   scale_y_continuous(expand=c(0,0),breaks=c(38.5,38.7,38.9))+   annotation_north_arrow(aes(location=location),                          style=north_arrow_minimal(fill=\"white\",                                                    line_col=\"white\",                                                    text_col=\"white\"),                          which_north=\"true\",                          height=unit(0.35,\"in\"),                          data=arrow_params)+   annotation_scale(aes(location=location,                    width_hint=width_hint,                    line_col=line_col,                    text_col=text_col),                    style=\"ticks\",                    data=scale_params)+   facet_wrap(~lyr,ncol=4)+   theme_minimal()+   theme(axis.text.x=element_text(size=10),         axis.text.y=element_text(size=10),         legend.position=\"bottom\") print(map2)"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"exporting-maps","dir":"Articles","previous_headings":"","what":"Exporting maps","title":"Visualizing Raster Data","text":"export figures R can add documents edit drawing program, need export external file. two best formats PNG, efficient raster graphics format, PDF, largely vector format, can also include embedded images. get sharp PNG output, usually want specify resolution least 300 points per inch using res argument.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"png-export","dir":"Articles","previous_headings":"Exporting maps","what":"PNG Export","title":"Visualizing Raster Data","text":"vector portions PDF plot always look sharp resulting file, resolution raster visualization set maxcell argument geom_spatraster created map .","code":"png(\"~/Downloads/snow_3panel_tidyterra.png\",     width=8,height=4,units=\"in\",res=300) map2 dev.off() #> agg_png  #>       2"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/pretty-maps.html","id":"pdf-export","dir":"Articles","previous_headings":"Exporting maps","what":"PDF Export","title":"Visualizing Raster Data","text":"","code":"pdf(\"~/Downloads/snow_3panel_tidyterra.pdf\",     width=8,height=4) map2 dev.off() #> agg_png  #>       2"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/sdp-cloud-data.html","id":"finding-datasets","dir":"Articles","previous_headings":"","what":"Finding datasets","title":"Accessing Cloud-based Datasets","text":"RMBL Spatial Data Platform provides 100 spatial data products, first challenge finding data relevant work. currently two ways find data: Searching browsing web-based Data Catalog RMBL’s website. Searching filtering datasets using built-catalog rSDP package.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/articles/sdp-cloud-data.html","id":"searching-the-sdp-catalog-from-r","dir":"Articles","previous_headings":"Finding datasets","what":"Searching the SDP Catalog from R","title":"Accessing Cloud-based Datasets","text":"can get data frame catalog information datasets working Rstudio, best way explore catalog opening Viewer pane. allows use built-filtering searching facilities RStudio Viewer. want filter catalog programmatically, can specify arguments sdp_get_catalog() return matching rows. example, wan return products vegetation, can specify: advanced filtering, can use regular expressions match particular products. “CatalogID” field provides concise, unique identifier data product, preferred way specify individual product. , CatalogID “R4D001” represents data product representing annual time-series snow persistence across Upper Gunnison domain.","code":"cat <- sdp_get_catalog() head(cat[,1:4]) #>   CatalogID  Release  Type                                        Product #> 1    R1D001 Release1 Hydro  Large Stream Flowlines (Multi-flow Direction) #> 2    R1D002 Release1 Hydro Large Stream Flowlines (Single-flow Direction) #> 3    R1D003 Release1 Hydro        Large Watersheds (Multi-flow Direction) #> 4    R1D004 Release1 Hydro              Multi-direction Flow Accumulation #> 5    R1D005 Release1 Hydro       Small Watersheds (Single Flow Direction) #> 6    R1D006 Release1 Hydro             Single Direction Flow Accumulation View(cat) veg_cat <- sdp_get_catalog(types=\"Vegetation\") head(veg_cat[,1:4]) #>    CatalogID  Release       Type                       Product #> 25    R1D025 Release1 Vegetation               Basic Landcover #> 26    R1D026 Release1 Vegetation Leaf-on Digital Surface Model #> 27    R1D027 Release1 Vegetation      Vegetation Canopy Height #> 40    R2D013 Release2 Vegetation        High-res Canopy Height #> 41    R2D014 Release2 Vegetation      Lidar Vegetation Metrics #> 54    R3D013 Release3 Vegetation              Understory Cover snow_cat <- cat[grepl(\"Snowpack Persist\",cat$Product),] head(snow_cat[,1:4]) #>     CatalogID  Release Type #> 75     R4D001 Release4 Snow #> 135    R4D061 Release4 Snow #> 136    R4D062 Release4 Snow #> 137    R4D063 Release4 Snow #>                                                             Product #> 75               Snowpack Persistence Day of Year Yearly Timeseries #> 135             Snowpack Persistence Day of Year Mean (1993 - 2022) #> 136 Snowpack Persistence Day of Year Standard Deviation (1993-2022) #> 137              Snowpack Persistence Uncertainty Yearly Timeseries"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/sdp-cloud-data.html","id":"getting-detailed-metadata","dir":"Articles","previous_headings":"Finding datasets","what":"Getting detailed metadata","title":"Accessing Cloud-based Datasets","text":"get detailed metadata item (beyond basic information provided Catalog), can use sdp_get_metadata() function.","code":"snow_meta <- sdp_get_metadata(\"R4D001\") print(snow_meta$qgis$extent$spatial) #> list() #> attr(,\"minx\") #> [1] \"305073\" #> attr(,\"miny\") #> [1] \"4256064\" #> attr(,\"maxz\") #> [1] \"0\" #> attr(,\"crs\") #> [1] \"EPSG:32613\" #> attr(,\"maxx\") #> [1] \"388098\" #> attr(,\"dimensions\") #> [1] \"2\" #> attr(,\"maxy\") #> [1] \"4328667\" #> attr(,\"minz\") #> [1] \"0\""},{"path":"https://rmbl-sdp.github.io/rSDP/articles/sdp-cloud-data.html","id":"visualizing-the-sdp-domains","dir":"Articles","previous_headings":"Finding datasets","what":"Visualizing the SDP domains","title":"Accessing Cloud-based Datasets","text":"currently provide SDP data products three different spatial domains. visualize boundaries domains, can construct web map shows . First need connect datasets stored cloud. ’ve got , can use terra::plet() function plot domains web map.","code":"GT_bound <- sf::st_read(\"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/GT_region_vect_1m.geojson\") #> Reading layer `GT_region_vect_1m' from data source  #>   `https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/GT_region_vect_1m.geojson'  #>   using driver `GeoJSON' #> Simple feature collection with 1 feature and 2 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: 327105 ymin: 4313359 xmax: 328312 ymax: 4314793 #> Projected CRS: WGS 84 / UTM zone 13N UER_bound <- sf::st_read(\"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/UER_region_vect_1m.geojson\") #> Reading layer `UER_region_vect_1m' from data source  #>   `https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/UER_region_vect_1m.geojson'  #>   using driver `GeoJSON' #> Simple feature collection with 1 feature and 2 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: 315965 ymin: 4298054 xmax: 337062 ymax: 4322641 #> Projected CRS: WGS 84 / UTM zone 13N UG_bound <- sf::st_read(\"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/UG_region_vect_1m.geojson\") #> Reading layer `UG_region_vect_1m' from data source  #>   `https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/UG_region_vect_1m.geojson'  #>   using driver `GeoJSON' #> Simple feature collection with 1 feature and 2 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: 307895 ymin: 4258017 xmax: 385679 ymax: 4326087 #> Projected CRS: WGS 84 / UTM zone 13N domain_bounds <- rbind(UG_bound,UER_bound,GT_bound) domain_bounds$Domain <- c(\"Upper Gunnison (UG)\",\"Upper East River (UER)\",\"Gothic Townsite (GT)\") domain_sv <- terra::vect(domain_bounds) terra::plet(domain_sv,\"Domain\",tiles=\"Esri.NatGeoWorldMap\",alpha=0.6,      main=\"SDP Spatial Domains\",      col=c(\"#6c42f5\",\"#c95773\",\"#59c957\"))"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/sdp-cloud-data.html","id":"connecting-to-data-in-the-cloud","dir":"Articles","previous_headings":"","what":"Connecting to data in the cloud","title":"Accessing Cloud-based Datasets","text":"SDP data products raster datasets available cloud storage service Amazon S3. many cases simplest way interact dataset connecting using web-based file system embedded terra package. make straightforward possible, provide function sdp_get_raster() connect data. default, function creates R object representing dataset without downloading whole thing locally.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/articles/sdp-cloud-data.html","id":"single-datasets","dir":"Articles","previous_headings":"Connecting to data in the cloud","what":"Single datasets","title":"Accessing Cloud-based Datasets","text":"connect dataset contains single layer, related layers stored single file, need provide sdp_get_raster CatalogID number data. load elevation map Upper Gunnison (UG) domain. can now see details structure dataset, including size (2401 x 27668 pixels), resolution (3m), coordinate reference system. Importantly can many common data visualizations manipulations dataset without download entire thing. example, want crop data area interest (say Gothic Townsite polygon loaded earlier), can accomplish downloading portion large raster covers polygon interest. notice source(s) field now says “memory”. means new dataset created longer lives cloud, now stored memory computer. cropped subset large fit memory, written temporary file. can now plot cropped raster dataset.","code":"UG_elev <- sdp_get_raster(\"R3D009\") UG_elev #> class       : SpatRaster  #> dimensions  : 24201, 27668, 1  (nrow, ncol, nlyr) #> resolution  : 3, 3  (x, y) #> extent      : 305082, 388086, 4256064, 4328667  (xmin, xmax, ymin, ymax) #> coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613)  #> source      : UG_dem_3m_v1.tif  #> name        : UG_dem_3m_v1 GT_elev <- crop(UG_elev,domain_sv[3,]) GT_elev #> class       : SpatRaster  #> dimensions  : 478, 402, 1  (nrow, ncol, nlyr) #> resolution  : 3, 3  (x, y) #> extent      : 327105, 328311, 4313358, 4314792  (xmin, xmax, ymin, ymax) #> coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613)  #> source(s)   : memory #> name        : UG_dem_3m_v1  #> min value   :     2864.029  #> max value   :     3174.758 plot(GT_elev)"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/sdp-cloud-data.html","id":"time-series-datasets","dir":"Articles","previous_headings":"Connecting to data in the cloud","what":"Time-series datasets","title":"Accessing Cloud-based Datasets","text":"Single-layer datasets relatively simple structure, many SDP data products provided time-series. maps provided daily, monthly, annual intervals. data products, need add additional arguments sdp_get_raster() specify temporal subsets return. example specifying years argument annual data return data layers representing desired years. code returns raster dataset representing snowpack persistence years 2018 2020: find time intervals included dataset, can examine catalog fields MinYear , MaxYear, MinDate MaxDate.","code":"cat[cat$CatalogID==\"R4D001\",1:4] #>    CatalogID  Release Type                                            Product #> 75    R4D001 Release4 Snow Snowpack Persistence Day of Year Yearly Timeseries snow_years <- sdp_get_raster(\"R4D001\",years=2018:2020,verbose=FALSE) snow_years #> class       : SpatRaster  #> dimensions  : 2689, 3075, 3  (nrow, ncol, nlyr) #> resolution  : 27, 27  (x, y) #> extent      : 305073, 388098, 4256064, 4328667  (xmin, xmax, ymin, ymax) #> coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613)  #> sources     : UG_snow_persistence_year_2018_27m_v1.tif   #>               UG_snow_persistence_year_2019_27m_v1.tif   #>               UG_snow_persistence_year_2020_27m_v1.tif   #> names       :      2018,     2019,      2020  #> min values  :  27.22007,  79.9462,  48.37198  #> max values  : 202.39381, 211.7621, 214.12854 cat[cat$TimeSeriesType %in% c(\"Yearly\",\"Monthly\",\"Daily\"),c(1,4,8:11)] #>     CatalogID                                                       Product #> 75     R4D001            Snowpack Persistence Day of Year Yearly Timeseries #> 76     R4D002                  Snowpack Onset Day of Year Yearly Timeseries #> 77     R4D003                           Snowpack Duration Yearly Timeseries #> 78     R4D004                   Maximum 2m Air Temperature Daily Timeseries #> 79     R4D005                   Minimum 2m Air Temperature Daily Timeseries #> 80     R4D006                 Average 2m Air Temperature Monthly Timeseries #> 81     R4D007                 Maximum 2m Air Temperature Monthly Timeseries #> 82     R4D008                 Minimum 2m Air Temperature Monthly Timeseries #> 83     R4D009        Air Temperature Freezing Degree-days Annual Timeseries #> 84     R4D010  Air Temperature Freezing Degree-days Early Season Timeseries #> 85     R4D011   Air Temperature Freezing Degree-days Late Season Timeseries #> 86     R4D012         Air Temperature Growing Degree-days Annual Timeseries #> 87     R4D013   Air Temperature Growing Degree-days Early Season Timeseries #> 88     R4D014    Air Temperature Growing Degree-days Late Season Timeseries #> 89     R4D015              Snow-free Freezing Degree-days Annual Timeseries #> 90     R4D016        Snow-free Freezing Degree-days Early Season Timeseries #> 91     R4D017         Snow-free Freezing Degree-days Late Season Timeseries #> 92     R4D018 Snow-free Freezing Degree-days 0-60 days Post-snow Timeseries #> 93     R4D019               Snow-free Growing Degree-days Annual Timeseries #> 94     R4D020         Snow-free Growing Degree-days Early Season Timeseries #> 95     R4D021          Snow-free Growing Degree-days Late Season Timeseries #> 96     R4D022   Snow-free Growing Degree-day 0-60 Days Post Snow Timeseries #> 137    R4D063            Snowpack Persistence Uncertainty Yearly Timeseries #> 138    R4D064                  Snowpack Onset Uncertainty Yearly Timeseries #>        MinDate    MaxDate MinYear MaxYear #> 75  1993-01-01 2022-09-30    1993    2022 #> 76  1992-10-01 2022-09-30    1993    2022 #> 77  1992-10-01 2022-09-30    1993    2022 #> 78  2001-11-01 2022-10-30    2001    2022 #> 79  2001-11-01 2022-10-30    2001    2022 #> 80  2001-11-01 2022-10-30    2001    2022 #> 81  2001-11-01 2022-10-30    2001    2022 #> 82  2001-11-01 2022-10-30    2001    2022 #> 83  2002-01-01 2022-12-31    2002    2022 #> 84  2002-01-01 2022-12-31    2002    2022 #> 85  2002-01-01 2022-12-31    2002    2022 #> 86  2002-01-01 2022-12-31    2002    2022 #> 87  2002-01-01 2022-12-31    2002    2022 #> 88  2002-01-01 2022-12-31    2002    2022 #> 89  2002-01-01 2022-12-31    2002    2022 #> 90  2002-01-01 2022-12-31    2002    2022 #> 91  2002-01-01 2022-12-31    2002    2022 #> 92  2002-01-01 2022-12-31    2002    2022 #> 93  2002-01-01 2022-12-31    2002    2022 #> 94  2002-01-01 2022-12-31    2002    2022 #> 95  2002-01-01 2022-12-31    2002    2022 #> 96  2002-01-01 2022-12-31    2002    2022 #> 137 1993-01-01 2022-09-30    1993    2022 #> 138 1992-10-01 2022-09-30    1993    2022"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/sdp-cloud-data.html","id":"when-should-you-download-data-locally","dir":"Articles","previous_headings":"Connecting to data in the cloud","what":"When should you download data locally?","title":"Accessing Cloud-based Datasets","text":"Although can perform many operations cloud-based datasets without downloading locally, operations may prohibitively slow. example, sampling 100 random points snow raster connected took approximately 25 seconds complete home internet connection data stored cloud: much slower operation locally stored data. deal situations like , included data download capabilities sdp_get_raster() function. Specifying download_files=TRUE along local download_path creates local copy data computer: ’s almost 40 times faster sample local dataset! example, time saved doesn’t quite make extra time download data, often larger operations. types operations might benefit downloading data locally: Operations use many pixels target datasets (e.g. resampling, reprojecting). Operations span large proportion extent raster (e.g. sampling values random points). performing multiple operations single source dataset (e.g. multiple raster algebra calculations single raster source).","code":"start_time <- Sys.time() snow_samp_cloud <- spatSample(snow_years,size=100) Sys.time() - start_time #> Time difference of 21.81979 secs snow_years_local <- sdp_get_raster(\"R4D001\",years=2018:2020,verbose=FALSE,                                    download_files=TRUE,                                    download_path=\"~/Downloads\") #> [1] \"All files exist locally. Specify `overwrite=TRUE` to overwrite existing files.\" #> [1] \"Loading raster from local paths.\" start_time <- Sys.time() snow_samp_local <- spatSample(snow_years_local,size=100) Sys.time() - start_time #> Time difference of 0.524817 secs"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"vector-vs-raster-data-","dir":"Articles","previous_headings":"","what":"Vector vs raster data.","title":"Wrangling Spatial Data","text":"fundamental distinction spatial data vector-formatted data (points, lines, polygons), raster-formatted data (images, arrays, grids). Vector data usually used represent data sparse space (say, points representing research sites, polygons representing watersheds). Raster data structures typically used measurements regular spacing, pixels satellite image elevation map. Figure 2. Raster vs vector data. Graphic Wegmann distinction raster vector data important two data types different ecosystems packages functions can work : widely-used package reading working vector data sf (Pebesma et al. 2018). package provides large number functions wrangling points, lines, polygons, including basic geometric operations like buffering, spatial joins. go-package wrangling raster data terra (Hijmans et al. 2020), provides efficient functions common raster operations like cropping, resampling. vector-data-focused functions terra, mirrored functions also available sf. Note packages wrangling spatial data R ecosystem (see comprehensive vew), found can usually accomplish almost everything need using two.","code":"knitr::include_graphics(\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Raster_vector_tikz.png/744px-Raster_vector_tikz.png\")"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"setting-up-the-workspace-and-dealing-with-dependencies-","dir":"Articles","previous_headings":"","what":"Setting up the workspace and dealing with dependencies.","title":"Wrangling Spatial Data","text":"can get terra sf packages installed successfully loaded computer well way. Mac Windows systems, usually simple : specify type=\"binary\" avoid common problems compiling packages rely external libraries. Unfortunately, things quite easy Linux machines binary versions source packages available. case, follow instructions install external libraries installing terra sf. rSDP package CRAN yet, need install latest version GitHub. ’ve got everything installed, can load libraries R workspace:","code":"install.packages(c(\"terra\",\"sf\"),type=\"binary\") remotes::install_github(\"rmbl-sdp/rSDP\") library(sf) library(terra) library(rSDP)"},{"path":[]},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"reading-in-vector-data","dir":"Articles","previous_headings":"Reading in raster and vector data.","what":"Reading in vector data","title":"Wrangling Spatial Data","text":"Vector spatial data comes large variety formats, nearly common ones can read using sf function st_read(). Behind scenes, st_read() relies fantastic GDAL library . ’s format GDAL can read, can get R st_read(). possibilities, two vector formats stand open-source broadly readable: geoJSON, open plain-text data format works really well small medium-sized datasets (hundred MB). GeoPackage, open geospatial database format based SQLITE can efficiently store larger complex datasets geoJSON, including related tables layers multiple geometry types. example, read small geoJSON file web representing hypothetical research sites vicinity Rocky Mountain Biological Laboratory. One nice things geoJSON format can read web-based source directly R: also work first downloaded file. just need replace URL file path computer. structure sf vector dataset extends basic structure R data frame, addition geometry column holds information points, lines, polygons associated feature. Attributes feature (“Attribute Table”) stored way tabular datasets R. upshot can use tools available wrangling data frames (subsetting, filtering, reshaping, etc.) sf objects without trouble. operations, geometry column sticky, means carried forward new derived datasets created. example, wanted create new dataset containing Name column sites use standard subsetting syntax select rows second column: didn’t specify bringing geometry column us, since ’s sticky came along ride.","code":"sites <- st_read(\"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/rSDP_example_points_latlon.geojson\") #> Reading layer `rSDP_example_points_latlon' from data source  #>   `https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/rSDP_example_points_latlon.geojson'  #>   using driver `GeoJSON' #> Simple feature collection with 9 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -106.9934 ymin: 38.95576 xmax: -106.9839 ymax: 38.96237 #> Geodetic CRS:  WGS 84 head(sites) #> Simple feature collection with 6 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -106.9934 ymin: 38.95807 xmax: -106.9898 ymax: 38.96237 #> Geodetic CRS:  WGS 84 #>   fid         Name                   geometry #> 1   1        Rocky POINT (-106.9904 38.96237) #> 2   2        Aspen POINT (-106.9898 38.96222) #> 3   3         Road POINT (-106.9903 38.96083) #> 4   4   BeaverPond POINT (-106.9934 38.96006) #> 5   5 GrassyMeadow POINT (-106.9927 38.96023) #> 6   6      Conifer  POINT (-106.992 38.95807) sites_name <- sites[,2] sites_name #> Simple feature collection with 9 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -106.9934 ymin: 38.95576 xmax: -106.9839 ymax: 38.96237 #> Geodetic CRS:  WGS 84 #>             Name                   geometry #> 1          Rocky POINT (-106.9904 38.96237) #> 2          Aspen POINT (-106.9898 38.96222) #> 3           Road POINT (-106.9903 38.96083) #> 4     BeaverPond POINT (-106.9934 38.96006) #> 5   GrassyMeadow POINT (-106.9927 38.96023) #> 6        Conifer  POINT (-106.992 38.95807) #> 7 WeatherStation POINT (-106.9859 38.95641) #> 8        Smelter POINT (-106.9839 38.95576) #> 9     Roundabout  POINT (-106.988 38.95808)"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"reading-in-raster-data","dir":"Articles","previous_headings":"Reading in raster and vector data.","what":"Reading in raster data","title":"Wrangling Spatial Data","text":"can use similar pattern get example raster dataset R. use sdp_get_raster() function read raster dataset representing ground elevation sea level, commonly called Digital Elevation Model DEM. One notable difference call st_read() default sdp_get_raster() doesn’t download full dataset locally, just file header basic information. Vignette “Accessing Cloud-based Datasets” provides detail accessing raster data using rSDP package.","code":"dem <- sdp_get_raster(\"R3D009\") dem #> class       : SpatRaster  #> dimensions  : 24201, 27668, 1  (nrow, ncol, nlyr) #> resolution  : 3, 3  (x, y) #> extent      : 305082, 388086, 4256064, 4328667  (xmin, xmax, ymin, ymax) #> coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613)  #> source      : UG_dem_3m_v1.tif  #> name        : UG_dem_3m_v1"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"re-projecting-vector-data","dir":"Articles","previous_headings":"","what":"Re-projecting vector data","title":"Wrangling Spatial Data","text":"One complexities geographic data maps (data make ) generally 2-dimensional, earth surprisingly lumpy 3-D object. upshot variety 2-D coordinate systems describe locations geographic relationships. coordinate system system different strengths weaknesses, means data collected different purposes different places often use different systems. example, point data read earlier uses Geographic (Geodetic) Coordinate System defines locations using latitude longitude. can verify looking last line information printed read data . line Geodetic CRS: WGS 84 means data coordinates stored common lat-lon coordinate system, World Geodetic System (WGS) agreed year 1984. Among reasons, coordinate system popular one used GPS satellite navigation systems. contrast, raster data another coordinate system, called Universal Transverse Mercator (UTM). “projected” coordinate system X Y coordinates represent distance meters arbitrary start location (often called datum). Figure 2. Geographic vs projected coordinate systems. geographic system (left) uses angular coordinates (latitude longitude) describing position 3D surface earth. projected system (right) ‘flattens’ globe measures coordinates arbitrary origin datum, represented right figure blue circle. Modified Lovelace et al. 2019. crs function terra package can retrieve coordinate reference system terra sf objects. , verify coordinate systems two datasets different: means want kind data wrangling operation involves datasets, need get coordinate system. Translating data one coordinate system another called projection. Hypothetically, either: Project raster dataset coordinate system vector Project vector dataset coordinate system raster practice, ’s usually better idea re-project vector data. almost always much faster operation. Moreover, unlike re-project vector datasets, re-projecting raster results slight loss information. re-project point data coordinate system raster: can see values coordinates sites_proj different original object sites, coordinate systems now identical raster vector data. success! means ready use datasets together.","code":"crs(sites) #> [1] \"GEOGCRS[\\\"WGS 84\\\",\\n    DATUM[\\\"World Geodetic System 1984\\\",\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    ID[\\\"EPSG\\\",4326]]\" crs(sites) == crs(dem) #> [1] FALSE sites_proj <- st_transform(sites,crs=crs(dem)) crs(sites_proj) == crs(dem) #> [1] TRUE head(sites_proj) #> Simple feature collection with 6 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 327280.5 ymin: 4314011 xmax: 327598 ymax: 4314484 #> Projected CRS: WGS 84 / UTM zone 13N #>   fid         Name                 geometry #> 1   1        Rocky POINT (327549.7 4314484) #> 2   2        Aspen   POINT (327598 4314467) #> 3   3         Road POINT (327550.8 4314314) #> 4   4   BeaverPond POINT (327280.5 4314235) #> 5   5 GrassyMeadow POINT (327342.2 4314252) #> 6   6      Conifer POINT (327403.2 4314011)"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"a-basic-plot","dir":"Articles","previous_headings":"Re-projecting vector data","what":"A basic plot","title":"Wrangling Spatial Data","text":"confirm successful getting two datasets coordinate system, can plot .  code , specifying argument ext plots spatial subset raster dataset. specify subset calling ext() function, returns rectangular region covered point dataset.","code":"plot(dem,main=\"Elevation (m)\",ext=ext(sites_proj)) points(sites_proj)"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"cropping-rasters-to-an-area-of-interest-","dir":"Articles","previous_headings":"","what":"Cropping rasters to an area of interest.","title":"Wrangling Spatial Data","text":"Now ’ve got raster vector datasets coordinate system, can operations use datasets. Let’s create spatial subset elevation map covers area points. use crop() function. second argument crop() specifies spatial extent want use crop raster. supply vector dataset, default behavior extract rectangular extent covers vector dataset, using ext() function behind scenes. Looking dimensions dem_crop, ’s now clear much smaller subset original data. ’s also now stored memory, subsequent operations subset quite fast.","code":"dem_crop <- crop(dem,sites_proj) dem_crop #> class       : SpatRaster  #> dimensions  : 248, 273, 1  (nrow, ncol, nlyr) #> resolution  : 3, 3  (x, y) #> extent      : 327279, 328098, 4313739, 4314483  (xmin, xmax, ymin, ymax) #> coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613)  #> source(s)   : memory #> name        : UG_dem_3m_v1  #> min value   :     2874.120  #> max value   :     3018.812"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"modifying-raster-data-","dir":"Articles","previous_headings":"","what":"Modifying raster data.","title":"Wrangling Spatial Data","text":"Now ’ve subset raster data, can perform lots different operations . example, terrain() function terra allows us compute topographic slope, identifying areas steep terrain:  can also perform arbitrary mathematical operations raster. example, wanted convert elevation map ’s default unit (meters) feet, multiply map appropriate conversion coefficient (1 meter = 3.28084 feet).","code":"dem_slope <- terrain(dem_crop,\"slope\") plot(dem_slope) dem_feet <- dem_crop * 3.28084 plot(c(dem_crop,dem_feet))"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"resampling-rasters-to-a-different-grid-","dir":"Articles","previous_headings":"","what":"Resampling rasters to a different grid.","title":"Wrangling Spatial Data","text":"Often want take raster datasets different sources put grid. operation called resampling. , need define grid output dataset choose method calculating resampled values locations grid cells. continuous data, common resampling method called bilinear interpolation. method defines new value pixels weighted average values four closest pixels source data. put practice, can use resample() function terra package. Figure 3. Bilinear interpolation. resampling strategy, new raster values computed weighted average four closest raster cells, closer cells higher weights. First, let’s load raster dataset lower resolution raster. data estimate day year seasonal snowpack finally melted spring.  dataset coordinate system elevation map, much lower spatial resolution. resample data finer resolution elevation map, use resample() function, defining elevation map template:  Obviously doesn’t create new information finer resolution. Instead, “smooths” original values fit new finer grid. Whether problem depends whether lot important variability dataset finer resolution.","code":"snow_2020 <- sdp_get_raster(\"R4D001\",years=2020) #> [1] \"Returning yearly dataset with 1 layers...\" snow_crop <- crop(snow_2020,sites_proj) plot(snow_crop) snow_res <- resample(snow_crop,dem_crop,method=\"bilinear\")  par(mfrow=c(1,2)) plot(snow_crop,main=\"Original (27m resolution)\",range=c(120,145)) plot(snow_res,main=\"Resampled (3m resolution)\",range=c(120,145))"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"re-projecting-rasters-to-a-different-coordinate-system-","dir":"Articles","previous_headings":"","what":"Re-projecting rasters to a different coordinate system.","title":"Wrangling Spatial Data","text":"Occasionally, need translate raster data coordinate systems. happens two stages: First, center points original raster cells re-projected new coordinate system. , new values computed projected grid using resampling method like used . demonstrate , let’s load climate dataset outside source. ClimateR package provides easy access variety gridded climate datasets. First need install GitHub: can grab example climate map PRISM dataset: case, coordinate system raster geographic (lat-long) coordinate system, ’s different others using. can verify : means need re-project data combining rest. operation quite slow, even relatively small raster dataset like one, now can crop result get layer extent resolution layers.","code":"#remotes::install_github(\"mikejohnson51/climateR\") #remotes::install_github(\"mikejohnson51/AOI\") library(climateR) library(AOI) buff <- st_as_sf(vect(ext(st_buffer(sites,dist=5000)))) st_crs(buff) <- st_crs(sites) prism <- getPRISM(AOI=buff,varname=\"tmax\",startDate=\"2020-05-01\",endDate=\"2020-05-01\") crs(prism$tmax) #> [1] \"GEOGCRS[\\\"unknown\\\",\\n    DATUM[\\\"unknown\\\",\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1,\\n                ID[\\\"EPSG\\\",9001]]]],\\n    PRIMEM[\\\"unknown\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433,\\n            ID[\\\"EPSG\\\",9122]]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"longitude\\\",east,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433,\\n                ID[\\\"EPSG\\\",9122]]],\\n        AXIS[\\\"latitude\\\",north,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433,\\n                ID[\\\"EPSG\\\",9122]]]]\" crs(prism$tmax)==crs(sites) #> [1] FALSE crs(prism$tmax)==crs(sites_proj) #> [1] FALSE prism_proj <- project(prism$tmax,dem,method=\"bilinear\",align=TRUE) prism_crop <- crop(prism_proj,dem_crop)"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"combining-rasters-into-a-single-dataset-","dir":"Articles","previous_headings":"","what":"Combining rasters into a single dataset.","title":"Wrangling Spatial Data","text":"wrangling, ’ve finally able assemble collection raster data consistent cell size resolution. can combine individual layers single SpatRaster object using c() function. data now “Analysis-Ready”! can use extract data field sites, fit spatial prediction models, variety tasks.","code":"full_stack_3m <- c(dem_crop,dem_slope,snow_res,prism_crop) names(full_stack_3m) <- c(\"Elevation\",\"Slope\",\"SnowPersist\",\"Tmax\") plot(full_stack_3m)"},{"path":"https://rmbl-sdp.github.io/rSDP/articles/wrangle-raster-data.html","id":"exporting-spatial-data","dir":"Articles","previous_headings":"","what":"Exporting spatial data","title":"Wrangling Spatial Data","text":"want explore wrangled data, often want GIS program like QGIS. Exporting data disk allows us : write single file disk four layers representing different raster datasets wrangled. Specifying “.tif” file extension writes file geoTIFF format, commonly used raster file format. can something similar wrangled vector data using st_read() function sf:","code":"writeRaster(full_stack_3m,\"~/Downloads/wrangled_raster_data.tif\", overwrite=TRUE) st_write(sites_proj,\"~/Downloads/wrangled_point_data.geojson\", delete_dsn=TRUE) #> Deleting source `/Users/ian/Downloads/wrangled_point_data.geojson' using driver `GeoJSON' #> Writing layer `wrangled_point_data' to data source  #>   `/Users/ian/Downloads/wrangled_point_data.geojson' using driver `GeoJSON' #> Writing 9 features with 2 fields and geometry type Point."},{"path":"https://rmbl-sdp.github.io/rSDP/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ian Breckheimer. Author, maintainer.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Breckheimer (2023). rSDP: Discover, Query, Subset Data RMBL Spatial Data Platform. https://github.com/rmbl-sdp/rSDP, https://rmbl-sdp.github.io/rSDP.","code":"@Manual{,   title = {rSDP: Discover, Query, and Subset Data from the RMBL Spatial Data Platform},   author = {Ian Breckheimer},   year = {2023},   note = {https://github.com/rmbl-sdp/rSDP, https://rmbl-sdp.github.io/rSDP}, }"},{"path":"https://rmbl-sdp.github.io/rSDP/index.html","id":"rsdp-","dir":"","previous_headings":"","what":"Discover, Query, and Subset Data from the RMBL Spatial Data Platform","title":"Discover, Query, and Subset Data from the RMBL Spatial Data Platform","text":"rSDP package provides simple interface discovering, querying, subsetting data products incorporated RMBL Spatial Data Platform. RMBL SDP provides set curated, high-resolution, high-fidelity geospatial datasets set domains Western Colorado (USA) vicinity Rocky Mountain Biological Laboratory. information RMBL SDP see . SDP data products provided geospatial raster datasets cloud-optimized Geotiff (COG) format. rSDP package provides functions access datasets cloud storage (Amazon S3) without downloading.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Discover, Query, and Subset Data from the RMBL Spatial Data Platform","text":"can install latest version rSDP GitHub : Installing development version leaflet package currently required web maps.","code":"# install.packages(\"remotes\") remotes::install_github(\"rmbl-sdp/rSDP\") remotes::install_github(\"rstudio/leaflet\")"},{"path":"https://rmbl-sdp.github.io/rSDP/index.html","id":"discovering-sdp-data-and-metadata","dir":"","previous_headings":"","what":"Discovering SDP Data and Metadata","title":"Discover, Query, and Subset Data from the RMBL Spatial Data Platform","text":"package provides functions sdp_get_catalog(), sdp_get_metadata() download information datasets currently available spatial attributes .","code":"library(rSDP)  ## Gets entries for vegetation data products in the Upper Gunnison (UG) domain. sdp_cat <- sdp_get_catalog(domains=\"UG\",                             types=\"Vegetation\",                            deprecated=FALSE,                            return_stac=FALSE) sdp_cat[,1:5] #>    CatalogID  Release       Type                       Product Domain #> 54    R3D013 Release3 Vegetation              Understory Cover     UG #> 55    R3D014 Release3 Vegetation       Vegetation Canopy Cover     UG #> 56    R3D015 Release3 Vegetation      Vegetation Canopy Height     UG #> 57    R3D016 Release3 Vegetation 20th Percentile Canopy Height     UG #> 58    R3D017 Release3 Vegetation 80th Percentile Canopy Height     UG #> 59    R3D018 Release3 Vegetation               Basic Landcover     UG #> 60    R3D019 Release3 Vegetation        October 2017 NAIP NDVI     UG #> 61    R3D020 Release3 Vegetation       Septober 2019 NAIP NDVI     UG #> 73     BM012 Basemaps Vegetation      Canopy Structure Basemap     UG #> 74     BM013 Basemaps Vegetation             Landcover Basemap     UG ## Grabs detailed metadata for a specific dataset. item_meta <- sdp_get_metadata(catalog_id=\"R1D001\",return_list=TRUE)  ## Prints the detailed description. item_description <- item_meta$qgis$abstract[[1]] print(item_description) #> [1] \"This map represents estimated stream flowlines from a hydrologically corrected digital elevation model. The lines were derived in GRASS GIS using a multi-direction algorithm that allows channel braiding. Each stream segment is identified by a unique integer. Stream lines were delineated for drainage areas greater than 512000 square meters.\\n\""},{"path":"https://rmbl-sdp.github.io/rSDP/index.html","id":"accessing-sdp-data-in-the-cloud","dir":"","previous_headings":"","what":"Accessing SDP data in the cloud.","title":"Discover, Query, and Subset Data from the RMBL Spatial Data Platform","text":"function sdp_get_raster(), creates R representations cloud-based datasets can used processing, returning SpatRaster can manipulated using functions terra package. Alternatively, can plot data web map:","code":"## Creates a `SpatRaster` object for a dataset. dem <- sdp_get_raster(catalog_id=\"R3D009\") terra::plot(dem) terra::plet(dem,tiles=\"Esri.WorldImagery\")"},{"path":"https://rmbl-sdp.github.io/rSDP/index.html","id":"downloading-sdp-data-locally","dir":"","previous_headings":"","what":"Downloading SDP data locally.","title":"Discover, Query, and Subset Data from the RMBL Spatial Data Platform","text":"default, sdp_get_raster() connects cloud-based datasets without downloading locally, specifying download_files=TRUE providing local file path download raster data disk. can sometimes speed operations prohibitively slow cloud-based data sources:","code":"## Creates a local `SpatRaster` dem_local <- sdp_get_raster(catalog_id=\"R3D009\",                             download_files=TRUE,                             download_path=\"~/Downloads\",                              overwrite=FALSE)"},{"path":"https://rmbl-sdp.github.io/rSDP/index.html","id":"extracting-samples-of-sdp-data","dir":"","previous_headings":"","what":"Extracting samples of SDP data.","title":"Discover, Query, and Subset Data from the RMBL Spatial Data Platform","text":"function sdp_extract_data() extracts samples datasets locations represented points, lines, polygons.  line polygon locations sdp_extract_data() summarizes raster values line polygon. default method computes mean value polygon, can also specify summary functions using sum_fun argument. can also return cell values intersecting line polygon specifying sum_fun=NULL. Passing argument exact=TRUE polygon features returns proportion raster cell included polygon (useful computing area-weighted means.)","code":"## Extracts values of an SDP dataset. elev <- sdp_get_raster(catalog_id=\"R3D009\") slope <- sdp_get_raster(catalog_id=\"R3D012\")  location_df <- data.frame(SiteName=c(\"Roaring Judy\",\"Gothic\",\"Galena Lake\"),                           Lat=c(38.716995,38.958446,39.021644),                           Lon=c(-106.853186,-106.988934,-107.072569)) location_sv <- terra::vect(location_df,geom=c(\"Lon\",\"Lat\"),crs=\"EPSG:4327\")  dem_sample <- sdp_extract_data(raster=elev,locations=location_sv) #> [1] \"Re-projecting locations to coordinate system of the raster.\" #> [1] \"Extracting data at 3 locations for 1 raster layers.\" #> [1] \"Extraction complete.\" slope_sample <- sdp_extract_data(raster=slope,locations=dem_sample) #> [1] \"Extracting data at 3 locations for 1 raster layers.\" #> [1] \"Extraction complete.\" plot(slope_sample$UG_dem_3m_v1,slope_sample$UG_dem_slope_1m_v1,xlab=\"Elevation (m).\",      ylab=\"Slope (degrees)\") slope <- sdp_get_raster(catalog_id=\"R3D012\")  location_poly <- data.frame(SiteName=c(\"Wet\",\"Conifer\",\"Rocky\"),                             WKT=c(\"POLYGON ((327651 4313638,327620 4313727,327693 4313759, 327651 4313638))\",                                    \"POLYGON ((327340 4314059,327450 4314026,327418 4313970,327340 4314059))\",                                    \"POLYGON ((328193 4314314,328285 4314274,328244 4314223, 328193 4314314))\")) location_poly_sv <- terra::vect(location_poly,geom=\"WKT\",crs=\"EPSG:32613\")  slope_site_mean <- sdp_extract_data(raster=slope,locations=location_poly_sv) #> [1] \"Extracting data at 3 locations for 1 raster layers.\" #> [1] \"Extraction complete.\" slope_site_sd <- sdp_extract_data(raster=slope,locations=slope_site_mean,                                   sum_fun=sd,bind=TRUE) #> [1] \"Extracting data at 3 locations for 1 raster layers.\" #> [1] \"Extraction complete.\" names(slope_site_sd) <- c(\"SiteName\",\"ID\",\"Slope_mean\",\"ID2\",\"Slope_sd\")  plot(slope_site_sd$Slope_mean,slope_site_sd$Slope_sd,xlab=\"Slope Mean (deg.)\",      ylab=\"Slope Standard Deviation\",pch=\"\") text(slope_site_sd$Slope_mean,slope_site_sd$Slope_sd,labels=slope_site_sd$SiteName) slope_allcells <- sdp_extract_data(raster=slope,locations=slope_site_mean,                                   sum_fun=NULL,exact=TRUE,bind=FALSE) #> [1] \"Extracting data at 3 locations for 1 raster layers.\" #> [1] \"Extraction complete.\" head(slope_allcells) #>   ID UG_dem_slope_1m_v1   fraction #> 1  1           4.609455 0.01733949 #> 2  1           6.018766 0.34246161 #> 3  1           9.753592 0.60725906 #> 4  1           3.104769 0.06934668 #> 5  1           6.362072 0.46575703 #> 6  1           6.617933 0.88677505"},{"path":"https://rmbl-sdp.github.io/rSDP/index.html","id":"working-with-raster-time-series","dir":"","previous_headings":"","what":"Working with raster time-series","title":"Discover, Query, and Subset Data from the RMBL Spatial Data Platform","text":"sdp_get_raster() sdp_extract_data() functions also provide convenience features subsetting time-series datasets day year.","code":"## Connects to rasters from a temporal subset of daily data. tmax <- sdp_get_raster(\"R4D004\",date_start=as.Date(\"2011-12-01\"),date_end=as.Date(\"2011-12-30\")) #> [1] \"Returning daily dataset with 30 layers...\"  ## Further subsets when extracting data tmax_sample <- sdp_extract_data(tmax,location_sv,date_start=as.Date(\"2011-12-01\"),date_end=as.Date(\"2011-12-20\")) #> [1] \"Re-projecting locations to coordinate system of the raster.\" #> [1] \"Extracting data at 3 locations for 20 raster layers.\" #> [1] \"Extraction complete.\" tmax_df <- as.data.frame(tmax_sample) dates <- as.Date(names(tmax_df)[3:ncol(tmax_sample)]) sites <- tmax_df$SiteName  ##Plots the result plot(dates,tmax_df[1,3:ncol(tmax_sample)],type=\"l\",ylab=\"Tmax (C)\",ylim=c(-15,7)) points(dates,tmax_df[2,3:ncol(tmax_sample)],type=\"l\",col=3) points(dates,tmax_df[3,3:ncol(tmax_sample)],type=\"l\",col=4) legend(\"bottomright\", legend=sites,col=c(1,3,4),bty=\"n\",lty=1) ##Retrieving rasters from a subset of years. snow_yearly <- sdp_get_raster(\"R4D001\",years=c(2012,2019)) #> [1] \"Returning yearly dataset with 2 layers...\" terra::plot(snow_yearly,range=c(60,230))"},{"path":"https://rmbl-sdp.github.io/rSDP/index.html","id":"extracting-data-from-large-time-series-datasets","dir":"","previous_headings":"","what":"Extracting data from large time-series datasets.","title":"Discover, Query, and Subset Data from the RMBL Spatial Data Platform","text":"extracting subsets large datasets, ’s sometimes good idea loop small subsets rather extracting single large raster object many (sometimes hundreds) layers.","code":"## Extracts with a single call. start1 <- Sys.time() tmax1 <- sdp_get_raster(\"R4D004\",date_start=as.Date(\"2004-10-01\"),date_end=as.Date(\"2004-10-31\")) #> [1] \"Returning daily dataset with 31 layers...\"  tmax_extr1 <- sdp_extract_data(tmax1,location_sv,verbose=FALSE) elapsed1 <- Sys.time() - start1  ## Loops over layers (different subset to avoid cacheing). start2 <- Sys.time() tmax2 <- sdp_get_raster(\"R4D004\",date_start=as.Date(\"2005-10-01\"),date_end=as.Date(\"2005-10-31\"),                         verbose=FALSE) locations_proj <- terra:::project(location_sv,\"EPSG:32613\")  extr_list <- list() for(i in 1:terra::nlyr(tmax2)){   extr_dat <- sdp_extract_data(tmax2[[i]],locations_proj,verbose=FALSE)[,3]   extr_list[[i]] <- extr_dat } tmax_extr2 <- do.call(cbind,extr_list) elapsed2 <- Sys.time() - start2  ## Loops over creating the raster object itself.  ## This is slower single threaded, but can be more easily made parallel. start3 <- Sys.time() days <- seq(as.Date(\"2006-10-01\"),as.Date(\"2006-10-31\"),by=\"day\") extr_list3 <- list() for(i in 1:length(days)){   tmax3 <- sdp_get_raster(\"R4D004\",date_start=days[i],date_end=days[i],verbose=FALSE)   extr_dat <- sdp_extract_data(tmax3,locations_proj,verbose=FALSE)[,3]   extr_list3[[i]] <- extr_dat } tmax_extr3 <- do.call(cbind,extr_list3) elapsed3 <- Sys.time() - start3  ## Parallel extraction via foreach. library(foreach) library(doParallel) #> Loading required package: iterators #> Loading required package: parallel library(sf) #> Linking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE  ## Can't pass SpatVector or SpatRaster objects via Foreach, so convert to sf. locations_sf <- st_as_sf(location_sv)  start4 <- Sys.time() cl <- parallel::makeCluster(4) doParallel::registerDoParallel(cl) days <- seq(as.Date(\"2007-10-01\"),as.Date(\"2007-10-31\"),by=\"day\")  extr_list4 <- foreach::foreach(i=1:length(days),.packages=c(\"sf\",\"terra\",\"rSDP\")) %dopar% {   tmax4 <- sdp_get_raster(\"R4D007\",date_start=days[i],                          date_end=days[i],verbose=FALSE)    locations_sv <- vect(locations_sf)    extr_dat <- sdp_extract_data(tmax4,locations=locations_sv,                                 verbose=FALSE,return_type=\"sf\")[,4]    (st_drop_geometry(extr_dat)) } parallel::stopCluster(cl) tmax_extr4 <- do.call(cbind,extr_list4) elapsed4 <- Sys.time() - start4  ##Collects timings. timings <- data.frame(approach=c(\"Single Call\",\"Looping sdp_extract_data()\",\"Looping over sdp_get_raster()\",\"Foreach\"),                       timing=c(elapsed1,elapsed2,elapsed3,elapsed4)) timings #>                        approach        timing #> 1                   Single Call 19.74518 secs #> 2    Looping sdp_extract_data() 27.44984 secs #> 3 Looping over sdp_get_raster() 29.54908 secs #> 4                       Foreach 35.03244 secs"},{"path":"https://rmbl-sdp.github.io/rSDP/reference/download_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Download SDP Datasets Locally — download_data","title":"Download SDP Datasets Locally — download_data","text":"Download SDP Datasets Locally","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/download_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download SDP Datasets Locally — download_data","text":"","code":"download_data(   urls,   output_dir,   return_status = TRUE,   resume = FALSE,   overwrite = FALSE,   ... )"},{"path":"https://rmbl-sdp.github.io/rSDP/reference/download_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download SDP Datasets Locally — download_data","text":"urls character vector URLs files download output_dir character vector destination file paths single path output files. return_status logical. function return data frame results download session? resume logical. function resume partial downloads? overwrite logical. function overwrite existing files? ... arguments passed curl::multi_download()","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/rSDP-package.html","id":null,"dir":"Reference","previous_headings":"","what":"rSDP: Discover, Query, and Subset Data from the RMBL Spatial Data Platform — rSDP-package","title":"rSDP: Discover, Query, and Subset Data from the RMBL Spatial Data Platform — rSDP-package","text":"rSDP package provides simplified interface discovering, querying, subsetting data products incorporated RMBL Spatial Data Platform. RMBL SDP provides set curated, high-resolution, high-fidelity geospatial datasets set domains Western Colorado (USA) vicinity [Rocky Mountain Biological Laboratory](https://rmbl.org). information RMBL SDP [see ](https://www.rmbl.org/scientists/resources/spatial-data-platform/). SDP data products provided geospatial raster datasets [cloud-optimized Geotiff]() (COG) format. rSDP package provides functions access datasets cloud storage (Amazon S3) without downloading.","code":""},{"path":[]},{"path":"https://rmbl-sdp.github.io/rSDP/reference/rSDP-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"rSDP: Discover, Query, and Subset Data from the RMBL Spatial Data Platform — rSDP-package","text":"Maintainer: Ian Breckheimer ikb@rmbl.org (ORCID)","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/replace_strngs.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace Multiple Strings in a Vector — replace_strngs","title":"Replace Multiple Strings in a Vector — replace_strngs","text":"Replace Multiple Strings Vector","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/replace_strngs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace Multiple Strings in a Vector — replace_strngs","text":"","code":"replace_strngs(x, y, vec, ...)"},{"path":"https://rmbl-sdp.github.io/rSDP/reference/replace_strngs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace Multiple Strings in a Vector — replace_strngs","text":"x vector strings replace y vector strings use instead vec initial character vector ... arguments passed gsub","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_extract_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract SDP raster data at a set of locations. — sdp_extract_data","title":"Extract SDP raster data at a set of locations. — sdp_extract_data","text":"Extract SDP raster data set locations.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_extract_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract SDP raster data at a set of locations. — sdp_extract_data","text":"","code":"sdp_extract_data(   raster,   locations,   date_start = NULL,   date_end = NULL,   years = NULL,   catalog_id = NULL,   url_template = NULL,   bind = TRUE,   return_type = \"SpatVector\",   method = \"bilinear\",   sum_fun = \"mean\",   verbose = TRUE,   ... )"},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_extract_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract SDP raster data at a set of locations. — sdp_extract_data","text":"raster class SpatRaster. raster dataset (class terra::SpatRaster) extract data . locations vector dataset (class terra::SpatVector sf::sf) containing points, lines, polygons sample raster data. date_start class Date. raster dataset daily monthly time-series, minimum date extracted data. date_end class Date. raster dataset daily monthly time-series, maximum date extracted data. years numeric. raster dataset annual time-series, years data requested. catalog_id character. Alternative method specifying dataset sample. IMPLEMENTED YET. url_template character. Alternative method specifying whic dataset sample. IMPLEMENTED YET. bind logical. extracted data bound inputs? , dataset returned ID field common input data. return_type character. Class output. return_type = 'SpatVector', retains geometry (class terra::SpatVector). return_type = 'sf' also retains geometry Simple Features object (class sf::sf). return_type = 'DataFrame' returns ordinary data frame. method Method extracting values (\"simple\" \"bilinear\"). \"simple\" values cell point falls returned. \"bilinear\" returned values interpolated values four nearest raster cells. Ignored locations represent lines polygons. sum_fun character function. Function use summarize raster cells overlap input features. Ignored extracting point. NULL, locations represent lines polygons, function returns cell values. verbose logical. function print messages process? ... arguments pass along terra::Extract()","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_extract_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract SDP raster data at a set of locations. — sdp_extract_data","text":"data.frame SpatVector extracted data. layer raster dataset column returned data.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_extract_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract SDP raster data at a set of locations. — sdp_extract_data","text":"","code":"## Loads a raster. sdp_rast <- sdp_get_raster(\"R4D004\",date_start=as.Date(\"2021-11-02\"),date_end=as.Date(\"2021-11-03\")) #> [1] \"Returning daily dataset with 2 layers...\"  ## Sampling locations. location_pts <- data.frame(SiteName=c(\"Roaring Judy\",\"Gothic\",\"Galena Lake\"),                           Lat=c(38.716995,38.958446,39.021644),                           Lon=c(-106.853186,-106.988934,-107.072569)) location_sv <- terra::vect(location_pts,geom=c(\"Lon\",\"Lat\"),crs=\"EPSG:4327\")  ## Extract data for sampling locations. sdp_extr_sv <- sdp_extract_data(sdp_rast,location_sv,return_spatvector=TRUE) #> [1] \"Re-projecting locations to coordinate system of the raster.\" #> [1] \"Extracting data at 3 locations for 2 raster layers.\" #> [1] \"Extraction complete.\" sdp_extr_sv #>  class       : SpatVector  #>  geometry    : points  #>  dimensions  : 3, 4  (geometries, attributes) #>  extent      : 320579.1, 338885.9, 4287002, 4321222  (xmin, xmax, ymin, ymax) #>  coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613)  #>  names       :     SiteName    ID 2021-11-02 2021-11-03 #>  type        :        <chr> <num>      <num>      <num> #>  values      : Roaring Judy     1      7.938      9.894 #>                      Gothic     2      3.788      7.493 #>                 Galena Lake     3     0.1095      1.442  ## Can also return a data frame. sdp_extr_df <- sdp_extract_data(sdp_rast,location_sv,return_spatvector=FALSE) #> [1] \"Re-projecting locations to coordinate system of the raster.\" #> [1] \"Extracting data at 3 locations for 2 raster layers.\" #> [1] \"Extraction complete.\" sdp_extr_df #>  class       : SpatVector  #>  geometry    : points  #>  dimensions  : 3, 4  (geometries, attributes) #>  extent      : 320579.1, 338885.9, 4287002, 4321222  (xmin, xmax, ymin, ymax) #>  coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613)  #>  names       :     SiteName    ID 2021-11-02 2021-11-03 #>  type        :        <chr> <num>      <num>      <num> #>  values      : Roaring Judy     1      7.938      9.894 #>                      Gothic     2      3.788      7.493 #>                 Galena Lake     3     0.1095      1.442"},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_catalog.html","id":null,"dir":"Reference","previous_headings":"","what":"Discover SDP data by downloading catalog information. — sdp_get_catalog","title":"Discover SDP data by downloading catalog information. — sdp_get_catalog","text":"Discover SDP data downloading catalog information.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_catalog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Discover SDP data by downloading catalog information. — sdp_get_catalog","text":"","code":"sdp_get_catalog(   domains = c(\"UG\", \"UER\", \"GT\"),   types = c(\"Mask\", \"Topo\", \"Vegetation\", \"Hydro\", \"Planning\", \"Radiation\", \"Snow\",     \"Climate\", \"Imagery\", \"Supplemental\"),   releases = c(\"Basemaps\", \"Release1\", \"Release2\", \"Release3\", \"Release4\"),   timeseries_types = c(\"Single\", \"Yearly\", \"Seasonal\", \"Monthly\", \"Daily\"),   deprecated = FALSE,   return_stac = FALSE )"},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_catalog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Discover SDP data by downloading catalog information. — sdp_get_catalog","text":"domains spatial domain desired data product. types type product return. releases release (group) data products return. timeseries_types datasets structured single datasets (e.g. Single), others time-series various periods (e.g.Monthly). deprecated older versions datasets returned, just latest version? return_stac IMPLEMENTED: results returned Spatio-temporal Asset Catalog? Otherwise return ordinary data frame.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_catalog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Discover SDP data by downloading catalog information. — sdp_get_catalog","text":"data frame containing basic catalog information matched data products.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_catalog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Discover SDP data by downloading catalog information. — sdp_get_catalog","text":"","code":"## Gets information on all current datasets. sdp_cat <- sdp_get_catalog() str(sdp_cat) #> 'data.frame':\t138 obs. of  18 variables: #>  $ CatalogID      : chr  \"R1D001\" \"R1D002\" \"R1D003\" \"R1D004\" ... #>  $ Release        : chr  \"Release1\" \"Release1\" \"Release1\" \"Release1\" ... #>  $ Type           : chr  \"Hydro\" \"Hydro\" \"Hydro\" \"Hydro\" ... #>  $ Product        : chr  \"Large Stream Flowlines (Multi-flow Direction)\" \"Large Stream Flowlines (Single-flow Direction)\" \"Large Watersheds (Multi-flow Direction)\" \"Multi-direction Flow Accumulation\" ... #>  $ Domain         : chr  \"UER\" \"UER\" \"UER\" \"UER\" ... #>  $ Resolution     : chr  \"1m\" \"1m\" \"1m\" \"1m\" ... #>  $ Deprecated     : logi  FALSE FALSE FALSE FALSE FALSE FALSE ... #>  $ MinDate        : Date, format: \"2018-07-16\" \"2018-07-16\" ... #>  $ MaxDate        : Date, format: \"2018-07-16\" \"2018-07-16\" ... #>  $ MinYear        : int  2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 ... #>  $ MaxYear        : int  2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 ... #>  $ TimeSeriesType : chr  \"Single\" \"Single\" \"Single\" \"Single\" ... #>  $ DataType       : chr  \"factor\" \"factor\" \"factor\" \"numeric\" ... #>  $ DataUnit       : chr  \"categorical\" \"categorical\" \"categorical\" \"square meters\" ... #>  $ DataScaleFactor: int  1 1 1 1 1 1 1 1 1 1 ... #>  $ DataOffset     : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ Data.URL       : chr  \"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release1/UER_streams_512k_mfd_1m_v2.tif\" \"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release1/UER_streams_512k_sfd_1m_v2.tif\" \"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release1/UER_basins_512k_mfd_1m_v2.tif\" \"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release1/UER_flow_accum_mfd_1m_v3.tif\" ... #>  $ Metadata.URL   : chr  \"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release1/UER_streams_512k_mfd_1m_v2_metadata.xml\" \"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release1/UER_streams_512k_sfd_1m_v2_metadata.xml\" \"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release1/UER_basins_512k_mfd_1m_v2_metadata.xml\" \"https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release1/UER_flow_accum_mfd_1m_v3_metadata.xml\" ...  ## Gets a subset of catalog entries for the Upper Gunnison (UG) domain. sdp_sub <- sdp_get_catalog(domains=\"UG\", types=\"Vegetation\",                           deprecated=FALSE,return_stac=FALSE) sdp_sub #>    CatalogID  Release       Type                       Product Domain #> 54    R3D013 Release3 Vegetation              Understory Cover     UG #> 55    R3D014 Release3 Vegetation       Vegetation Canopy Cover     UG #> 56    R3D015 Release3 Vegetation      Vegetation Canopy Height     UG #> 57    R3D016 Release3 Vegetation 20th Percentile Canopy Height     UG #> 58    R3D017 Release3 Vegetation 80th Percentile Canopy Height     UG #> 59    R3D018 Release3 Vegetation               Basic Landcover     UG #> 60    R3D019 Release3 Vegetation        October 2017 NAIP NDVI     UG #> 61    R3D020 Release3 Vegetation       Septober 2019 NAIP NDVI     UG #> 73     BM012 Basemaps Vegetation      Canopy Structure Basemap     UG #> 74     BM013 Basemaps Vegetation             Landcover Basemap     UG #>    Resolution Deprecated    MinDate    MaxDate MinYear MaxYear TimeSeriesType #> 54         3m      FALSE 2019-09-07 2019-09-07    2019    2019         Single #> 55         3m      FALSE 2019-09-07 2019-09-07    2019    2019         Single #> 56         1m      FALSE 2019-09-07 2019-09-07    2019    2019         Single #> 57         3m      FALSE 2019-09-07 2019-09-07    2019    2019         Single #> 58         3m      FALSE 2019-09-07 2019-09-07    2019    2019         Single #> 59         1m      FALSE 2019-09-07 2019-09-07    2019    2019         Single #> 60         1m      FALSE 2019-09-07 2019-09-07    2019    2019         Single #> 61         1m      FALSE 2019-09-07 2019-09-07    2019    2019         Single #> 73         2m      FALSE 2019-09-07 2019-09-07    2019    2019         Single #> 74         2m      FALSE 2019-09-07 2019-09-07    2019    2019         Single #>    DataType    DataUnit DataScaleFactor DataOffset #> 54  numeric  proportion               1          0 #> 55  numeric  proportion               1          0 #> 56  numeric      meters               1          0 #> 57  numeric      meters               1          0 #> 58  numeric      meters               1          0 #> 59   factor categorical               1          0 #> 60  numeric    unitless               1          0 #> 61  numeric    unitless               1          0 #> 73  numeric    unitless               1          0 #> 74  numeric    unitless               1          0 #>                                                                                                   Data.URL #> 54 https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_canopy_2mcover_3m_v2.tif #> 55   https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_canopy_cover_3m_v3.tif #> 56  https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_canopy_height_1m_v2.tif #> 57    https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_canopy_ht20_3m_v2.tif #> 58    https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_canopy_ht80_3m_v4.tif #> 59      https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_landcover_1m_v4.tif #> 60   https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_ndvi_oct2017_1m_v1.tif #> 61  https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_ndvi_sept2019_1m_v2.tif #> 73             https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/basemaps/UG_canopy_basemap_v3.tif #> 74          https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/basemaps/UG_landcover_basemap_v3.tif #>                                                                                                        Metadata.URL #> 54 https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_canopy_2mcover_3m_v2_metadata.xml #> 55   https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_canopy_cover_3m_v3_metadata.xml #> 56  https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_canopy_height_1m_v2_metadata.xml #> 57    https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_canopy_ht20_3m_v2_metadata.xml #> 58    https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_canopy_ht80_3m_v4_metadata.xml #> 59      https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_landcover_1m_v4_metadata.xml #> 60   https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_ndvi_oct2017_1m_v1_metadata.xml #> 61  https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release3/UG_ndvi_sept2019_1m_v2_metadata.xml #> 73             https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/basemaps/UG_canopy_basemap_v3_metadata.xml #> 74          https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/basemaps/UG_landcover_basemap_v3_metadata.xml"},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Download detailed geospatial metadata for SDP Datasets. — sdp_get_metadata","title":"Download detailed geospatial metadata for SDP Datasets. — sdp_get_metadata","text":"Download detailed geospatial metadata SDP Datasets.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download detailed geospatial metadata for SDP Datasets. — sdp_get_metadata","text":"","code":"sdp_get_metadata(catalog_id, return_list = TRUE)"},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download detailed geospatial metadata for SDP Datasets. — sdp_get_metadata","text":"catalog_id unique Catalog ID code desired dataset. return_list Logical. TRUE, output parsed R list object.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download detailed geospatial metadata for SDP Datasets. — sdp_get_metadata","text":"nested list (return_list=TRUE) XML document (return_list=FALSE) containing detailed geospatial metadata dataset.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download detailed geospatial metadata for SDP Datasets. — sdp_get_metadata","text":"","code":"##Get metadata for a specific item. sdp_get_metadata(catalog_id=\"R1D001\",return_list=TRUE) #> $qgis #> $qgis$identifier #> $qgis$identifier[[1]] #> [1] \"/vsicurl/https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/released/release1/UER_streams_512k_mfd_1m_v2.tif\" #>  #>  #> $qgis$parentidentifier #> list() #>  #> $qgis$language #> $qgis$language[[1]] #> [1] \"en\" #>  #>  #> $qgis$type #> $qgis$type[[1]] #> [1] \"dataset\" #>  #>  #> $qgis$title #> $qgis$title[[1]] #> [1] \"Map of Multi-direction Stream Flowlines from the 2018 NEON AOP Digital Elevation Model\" #>  #>  #> $qgis$abstract #> $qgis$abstract[[1]] #> [1] \"This map represents estimated stream flowlines from a hydrologically corrected digital elevation model. The lines were derived in GRASS GIS using a multi-direction algorithm that allows channel braiding. Each stream segment is identified by a unique integer. Stream lines were delineated for drainage areas greater than 512000 square meters.\\n\" #>  #>  #> $qgis$keywords #> $qgis$keywords$keyword #> $qgis$keywords$keyword[[1]] #> [1] \"Environment\" #>  #>  #> $qgis$keywords$keyword #> $qgis$keywords$keyword[[1]] #> [1] \"Geoscientific Information\" #>  #>  #> $qgis$keywords$keyword #> $qgis$keywords$keyword[[1]] #> [1] \"Inland Waters\" #>  #>  #> $qgis$keywords$keyword #> $qgis$keywords$keyword[[1]] #> [1] \"Society\" #>  #>  #> attr(,\"vocabulary\") #> [1] \"gmd:topicCategory\" #>  #> $qgis$contact #> $qgis$contact$name #> $qgis$contact$name[[1]] #> [1] \"Ian Breckheimer\" #>  #>  #> $qgis$contact$organization #> $qgis$contact$organization[[1]] #> [1] \"Rocky Mountain Biological Laboratory\" #>  #>  #> $qgis$contact$position #> $qgis$contact$position[[1]] #> [1] \"Research Scientist\" #>  #>  #> $qgis$contact$voice #> list() #>  #> $qgis$contact$fax #> list() #>  #> $qgis$contact$email #> $qgis$contact$email[[1]] #> [1] \"ikb@rmbl.org\" #>  #>  #> $qgis$contact$role #> $qgis$contact$role[[1]] #> [1] \"owner\" #>  #>  #>  #> $qgis$links #> $qgis$links$link #> list() #> attr(,\"url\") #> [1] \"https://rmbl.org/data\" #> attr(,\"name\") #> [1] \"URL\" #> attr(,\"format\") #> [1] \"\" #> attr(,\"size\") #> [1] \"\" #> attr(,\"type\") #> [1] \"WWW:LINK\" #> attr(,\"mimeType\") #> [1] \"\" #> attr(,\"description\") #> [1] \"Spatial Data Platform Description\" #>  #>  #> $qgis$fees #> list() #>  #> $qgis$license #> $qgis$license[[1]] #> [1] \"Creative Commons Attribution 4.0\" #>  #>  #> $qgis$encoding #> list() #>  #> $qgis$crs #> $qgis$crs$spatialrefsys #> $qgis$crs$spatialrefsys$wkt #> $qgis$crs$spatialrefsys$wkt[[1]] #> [1] \"PROJCRS[\\\"WGS 84 / UTM zone 13N\\\",BASEGEOGCRS[\\\"WGS 84\\\",DATUM[\\\"World Geodetic System 1984\\\",ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,LENGTHUNIT[\\\"metre\\\",1]]],PRIMEM[\\\"Greenwich\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],ID[\\\"EPSG\\\",4326]],CONVERSION[\\\"UTM zone 13N\\\",METHOD[\\\"Transverse Mercator\\\",ID[\\\"EPSG\\\",9807]],PARAMETER[\\\"Latitude of natural origin\\\",0,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8801]],PARAMETER[\\\"Longitude of natural origin\\\",-105,ANGLEUNIT[\\\"degree\\\",0.0174532925199433],ID[\\\"EPSG\\\",8802]],PARAMETER[\\\"Scale factor at natural origin\\\",0.9996,SCALEUNIT[\\\"unity\\\",1],ID[\\\"EPSG\\\",8805]],PARAMETER[\\\"False easting\\\",500000,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8806]],PARAMETER[\\\"False northing\\\",0,LENGTHUNIT[\\\"metre\\\",1],ID[\\\"EPSG\\\",8807]]],CS[Cartesian,2],AXIS[\\\"(E)\\\",east,ORDER[1],LENGTHUNIT[\\\"metre\\\",1]],AXIS[\\\"(N)\\\",north,ORDER[2],LENGTHUNIT[\\\"metre\\\",1]],USAGE[SCOPE[\\\"unknown\\\"],AREA[\\\"World - N hemisphere - 108°W to 102°W - by country\\\"],BBOX[0,-108,84,-102]],ID[\\\"EPSG\\\",32613]]\" #>  #>  #> $qgis$crs$spatialrefsys$proj4 #> $qgis$crs$spatialrefsys$proj4[[1]] #> [1] \"+proj=utm +zone=13 +datum=WGS84 +units=m +no_defs\" #>  #>  #> $qgis$crs$spatialrefsys$srsid #> $qgis$crs$spatialrefsys$srsid[[1]] #> [1] \"3097\" #>  #>  #> $qgis$crs$spatialrefsys$srid #> $qgis$crs$spatialrefsys$srid[[1]] #> [1] \"32613\" #>  #>  #> $qgis$crs$spatialrefsys$authid #> $qgis$crs$spatialrefsys$authid[[1]] #> [1] \"EPSG:32613\" #>  #>  #> $qgis$crs$spatialrefsys$description #> $qgis$crs$spatialrefsys$description[[1]] #> [1] \"WGS 84 / UTM zone 13N\" #>  #>  #> $qgis$crs$spatialrefsys$projectionacronym #> $qgis$crs$spatialrefsys$projectionacronym[[1]] #> [1] \"utm\" #>  #>  #> $qgis$crs$spatialrefsys$ellipsoidacronym #> $qgis$crs$spatialrefsys$ellipsoidacronym[[1]] #> [1] \"EPSG:7030\" #>  #>  #> $qgis$crs$spatialrefsys$geographicflag #> $qgis$crs$spatialrefsys$geographicflag[[1]] #> [1] \"false\" #>  #>  #>  #>  #> $qgis$extent #> $qgis$extent$spatial #> list() #> attr(,\"dimensions\") #> [1] \"2\" #> attr(,\"minx\") #> [1] \"315130\" #> attr(,\"minz\") #> [1] \"0\" #> attr(,\"maxx\") #> [1] \"337845\" #> attr(,\"maxz\") #> [1] \"0\" #> attr(,\"miny\") #> [1] \"4297480\" #> attr(,\"maxy\") #> [1] \"4323209\" #> attr(,\"crs\") #> [1] \"EPSG:32613\" #>  #> $qgis$extent$temporal #> $qgis$extent$temporal$period #> $qgis$extent$temporal$period$start #> list() #>  #> $qgis$extent$temporal$period$end #> list() #>  #>  #>  #>  #> attr(,\"version\") #> [1] \"3.10.2-A Coruña\" #>"},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_raster.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an R object representing an SDP dataset. — sdp_get_raster","title":"Create an R object representing an SDP dataset. — sdp_get_raster","text":"Create R object representing SDP dataset.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_raster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an R object representing an SDP dataset. — sdp_get_raster","text":"","code":"sdp_get_raster(   catalog_id = NULL,   url = NULL,   years = NULL,   months = NULL,   date_start = NULL,   date_end = NULL,   verbose = TRUE,   download_files = FALSE,   download_path = NULL,   overwrite = FALSE,   ... )"},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_raster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an R object representing an SDP dataset. — sdp_get_raster","text":"catalog_id character. single valid catalog number SDP dataset. CatalogID field information returned sdp_get_catalog(). url character. valid URL (e.g. https://path..dataset.tif) cloud-based dataset. specify either catalog_id url, . years numeric. annual time-series data, numeric vector specifying years return. default NULL returns available years. months numeric. monthly time-series data, numeric vector specifying months data return. default NULL returns available months. date_start class Date. daily time-series data, first day data return. date_end class Date. daily time-series data, last day data return. verbose logical. function print status progress messages? download_files logical. function download files disk? default FALSE creates cloud-based representations data without downloading. download_path character. Destination path downloaded files. can relative absolute path. overwrite logical. files names datasets overwritten download_path? FALSE, function skip downloading files already exist destination. ... arguments pass terra::rast() function.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_raster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an R object representing an SDP dataset. — sdp_get_raster","text":"R object (class terra::SpatRaster) representing raster dataset.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_raster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an R object representing an SDP dataset. — sdp_get_raster","text":"Files headers read cloud-based datasets using terra package, full dataset downloaded locally unless download_files=TRUE. Instead terra uses web-based file system embedded GDAL (VSICURL) access datasets cloud. large datasets slow network connections, function might take minute complete. Specifying local downloads download_files=TRUE might efficient multi-layer data, can take lots disk space.","code":""},{"path":"https://rmbl-sdp.github.io/rSDP/reference/sdp_get_raster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an R object representing an SDP dataset. — sdp_get_raster","text":"","code":"## Lookup catalog number for a dataset. cat <- sdp_get_catalog(domain='UG',type='Vegetation') lc_id <- cat$CatalogID[cat$Product=='Basic Landcover']  ## Connect to the dataset without downloading landcover <- sdp_get_raster(lc_id) landcover #> class       : SpatRaster  #> dimensions  : 72603, 83004, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 305082, 388086, 4256064, 4328667  (xmin, xmax, ymin, ymax) #> coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613)  #> source      : UG_landcover_1m_v4.tif  #> color table : 1  #> name        : UG_landcover_1m_v4"},{"path":"https://rmbl-sdp.github.io/rSDP/news/index.html","id":"rsdp-01","dir":"Changelog","previous_headings":"","what":"rSDP 0.1","title":"rSDP 0.1","text":"Initial public release beta testing. Feedback welcome! Please add issues find GitHub Repository package. possible, please include reproducible example Added NEWS.md file track changes package.","code":""}]
