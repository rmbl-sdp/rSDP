---
title: "Wrangling SDP Data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Wrangling Raster Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Getting spatial data into the right shape and format for analysis ("data wrangling") comes with some unique challenges relative to tabular, spreadsheet-style data. Spatial data comes in a variety of formats, can have complex structure. It's also sometimes be very large (Gigabytes or more)! Luckly, R comes with a mature set of tools for wrangling spatial data. 

![Figure 1. Illustration by Allison Horst.](https://rzine.fr/publication/20210204_learnr_dplyr_allison_horst/featured_hu565622b82dee564ffeba1cec01107210_807144_720x0_resize_lanczos_3.png)

This Vignette covers some common workflows encountered in the wrangling process. Note that although we use data from the RMBL Spatial Data Platform (accessed using the `rSDP` package), these basic workflows apply whenever you are dealing with spatial data in R from any source.

## Vector vs raster data. 

The most fundamental distinction in spatial data is between *vector-formatted data* (points, lines, polygons), and *raster-formatted data* (images, arrays, grids). Vector data is usually used to represent data that is sparse in space (say, points representing research sites, or polygons representing watersheds). Raster data structures are typically used when we have measurements at a regular spacing, such as the pixels of a satellite image or of an elevation map. 

This distinction between raster and vector data is important because these two data types have different ecosystems of packages and functions that can work with them:
- The most widely-used package for reading and working with vector data is `sf` (Pebesma et al. 2018). This package provides a large number of functions for wrangling points, lines, and polygons, including basic geometric operations like buffering, and spatial joins. 
- The go-to package for wrangling raster data is `terra` (Hijmans et al. 2020), which provides efficient functions for common raster operations like cropping, and resampling. There are a few vector-data-focused functions in `terra`, but most of these are mirrored by functions also available in `sf`.

Note that these are not the only packages for wrangling spatial data in the `R` ecosystem (see [here](https://cran.r-project.org/web/views/Spatial.html) for a more comprehensive vew), but we have found that we can usually accomplish almost everything we need to using these two.

## Setting up the workspace and dealing with dependencies.

If you can get the `terra` and `sf` packages installed and successfully loaded on your computer you are well on your way. On Mac and Windows systems, this is usually as simple as:

```{r libraries,eval=FALSE}
install.packages(c("terra","sf"),type="binary")
```

We specify `type="binary"` to avoid common problems with compiling these packages that rely on external libraries. Unfortunately, things are not quite as easy on Linux machines for which binary versions of the source packages are not available. In that case, you should follow the [instructions here](https://rtask.thinkr.fr/installation-of-r-4-2-on-ubuntu-22-04-lts-and-tips-for-spatial-packages/#Install_packages_for_spatial_data_analyses_in_Ubuntu) to install these external libraries *before* installing `terra` and `sf`.

The rSDP package is not up on CRAN yet, so you will need to install the latest version from GitHub.

```{r rSDP}
remotes::install_github("rmbl-sdp/rSDP")
```

Once you've got everything installed, you can load the libraries into your R workspace:

```{r workspace,message=FALSE,warning=FALSE}
library(sf)
library(terra)
library(rSDP)
```

## Reading in raster and vector data.

Vector spatial data comes in a large variety of formats, but nearly all of the common ones can be read in using the `sf` function `st_read()`. Behind the scenes, `st_read()` relies on the fantastic [`GDAL` library](https://gdal.org/) for this. If it's in [a format GDAL can read](https://gdal.org/drivers/vector/index.html), you can get it into R with `st_read()`. 

Of all the possibilities, two vector formats stand out for being open source and broadly readable:
* [geoJSON](https://en.wikipedia.org/wiki/GeoJSON), an open plain-text data format that works really well for small to medium-sized datasets (up to a few hundred MB).
* [GeoPackage](https://www.geopackage.org/), an open geospatial database format based on SQLITE that can efficiently store larger and more complex datasets than geoJSON, including related tables and layers with multiple geometry types.

In this example, we will read a small geoJSON file from the web representing hypothetical research sites in the vicinity of Rocky Mountain Biological Laboratory. One of the nice things about the geoJSON format is that it can be read from a web-based source directly into R:

```{r read vector}
sites <- st_read("https://rmbl-sdp.s3.us-east-2.amazonaws.com/data_products/supplemental/rSDP_example_points_latlon.geojson")
```
This would also work if you first downloaded the file. You would just need to replace the URL with the file path on your computer.

We can use a similar pattern to get an example raster dataset into R. Here we will use the `sdp_get_raster()` function to read in a raster dataset representing the ground elevation above sea level, commonly called a Digital Elevation Model or DEM. 

```{r get dem}
dem <- sdp_get_raster("R3D009")
dem
```
One notable difference with the call to `st_read()` is that by default `sdp_get_raster()` doesn't download the full dataset locally, just the file header with basic information. The Vignette "Accessing Cloud-based Datasets" provides more detail on accessing raster data using the rSDP package.

## Re-projecting vector data

One of the complexities of geographic data is that maps (and the data that make them up) are generally 2-dimensional, while the earth is a [surprisingly lumpy](https://en.wikipedia.org/wiki/Geoid) 3-D object. The upshot is there are a variety of 2-D [coordinate systems](https://mgimond.github.io/Spatial/chp09_0.html) that describe locations and geographic relationships. Each coordinate system system has different strengths and weaknesses, which means that data collected for different purposes or in different places often use different systems. 

In this example, the point data we read in earlier uses a Geographic (Geodetic) Coordinate System that defines locations using latitude and longitude. You can verify this by looking at the last line of the information printed when we read the data in. The line `Geodetic CRS: WGS 84` means that this data has coordinates stored in the most common lat-lon coordinate system, the [World Geodetic System](https://en.wikipedia.org/wiki/World_Geodetic_System) (WGS) agreed to in the year 1984. Among other reasons, this coordinate system is popular because it is the one used by GPS and other satellite navigation systems.

In contrast, the raster data is in another coordinate system, called Universal Transverse Mercator or (UTM). This is a "projected" coordinate system

```{r crs compare}
crs(sites)
crs(dem)
```


## Cropping rasters to an area of interest.

## Resampling rasters to a different grid.

## Re-projecting to a different coordinate system.

## Combining everything into a single "stack".



```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(rSDP)
```
